{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "CPython 3.6.7\n",
      "IPython 7.4.0\n",
      "\n",
      "numpy 1.16.2\n",
      "scipy 1.2.1\n",
      "pandas 0.24.2\n",
      "matplotlib 3.0.3\n",
      "sklearn 0.20.3\n",
      "\n",
      "compiler   : GCC 8.2.0\n",
      "system     : Linux\n",
      "release    : 4.9.93-boot2docker\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 2\n",
      "interpreter: 64bit\n",
      "Git hash   :\n"
     ]
    }
   ],
   "source": [
    "# pip install watermark\n",
    "%load_ext watermark\n",
    "%watermark -v -m -p numpy,scipy,pandas,matplotlib,sklearn -g \n",
    "#,statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import datetime\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================================================\r\n",
      "Advanced comparator SimadynD <=> TDC software version: v.11 \r\n",
      "Author: Anton Tushev \r\n",
      "Comparison result made from /notebooks/pinda/data/test StrucG folder \r\n",
      "TDC data file is 'TX04_fixed_v1.csv' \r\n",
      "List of SimadynD subfolders for parsing is ['tx04'] \r\n",
      "List of ignored charts is ['@SIMD'] \r\n",
      "===================================================================================\n"
     ]
    }
   ],
   "source": [
    "COMPARATOR_AUTHOR = \"Anton Tushev\" \n",
    "COMPARATOR_VERSION = \"v.11\"\n",
    "PATH_TO_DATA = '/notebooks/pinda/data'\n",
    "#PATH_TO_STRUCG = '/notebooks/pinda/data/alcanc26_03_2019'\n",
    "PATH_TO_STRUCG = '/notebooks/pinda/data/test'\n",
    "PATH_TO_REPORTS = '/notebooks/pinda/reports'\n",
    "FILE_NAME_DATA1 = 'TX04_fixed_v1.csv'\n",
    "SD_RACK_NAMES = ['tx04']\n",
    "FILE_NAME_TEMP1 = 'TX04_@progress_bkup.csv'\n",
    "#FILE_NAME_DATA1 = 'test.csv'\n",
    "IGNORE_CHART = ['@SIMD']\n",
    "SKIP_EQUAL = True\n",
    "SKIP_BLOCK_NEXST = True\n",
    "SKIP_SIGNAL_NFND = True\n",
    "SKIP_TYPE_STR = True\n",
    "SKIP_CHART_NFND = True\n",
    "COMPARATOR_README = \"===================================================================================\\\n",
    "\\r\\nAdvanced comparator SimadynD <=> TDC software version: %s \\r\\nAuthor: %s \\\n",
    "\\r\\nComparison result made from %s StrucG folder \\\n",
    "\\r\\nTDC data file is '%s' \\\n",
    "\\r\\nList of SimadynD subfolders for parsing is %s \\\n",
    "\\r\\nList of ignored charts is %s \\\n",
    "\\r\\n===================================================================================\\\n",
    "\"%(COMPARATOR_VERSION,COMPARATOR_AUTHOR,PATH_TO_STRUCG,FILE_NAME_DATA1,SD_RACK_NAMES,IGNORE_CHART)\n",
    "print(COMPARATOR_README)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types  ['BOOL' 'REAL' 'SDTIME' 'WORD' 'INT' 'DINT' 'GLOBAL' 'STRING' 'DWORD'\n",
      " 'BYTE']\n",
      "Charts  ['ENCC_1' 'ENBRU1' 'ENBRI1' 'ENBEA1' 'BGT__1' '@SEND1' 'ENGAU1' 'ENGN11'\n",
      " 'ENMB_1' 'ENOSW1' 'ENGUA1' 'ENHDR1' 'ENIHW1' 'ENINS1' 'ENEXT1' 'ENENT1'\n",
      " 'ENSR_1' 'ENSPH1' 'ENSCD1' 'ENPIN1' 'ENPEL1' 'ENPAR1' 'ENISW1' 'ENLAP1'\n",
      " 'ENMA_1' 'ENMAN1' 'ENOHW1' 'ENSTR1' 'ENTEM1' 'ENTUR1' 'MESY_1' 'MONIM1'\n",
      " 'MONIW1' 'SERV_1' 'VISU_1' 'WPS__1' 'ENISW_MSU' 'ENDIA1' 'ENCRA1'\n",
      " 'ENCPT1' 'ENCPS1' 'ENCPP1' 'ENCPM1' 'ENCPH1' 'ENCPC1' 'ENCPA1' 'ENCOO1'\n",
      " 'ENMG_1' 'ENMC_1' 'ENMD_1' 'ENME_1' 'ENMF_1' '@SEND2' 'EXBAN2' 'EXBBH2'\n",
      " 'EXBBY2' 'EXBEA2' 'EXBW_2' 'EXBWA2' 'EXBWT2' 'EXCC_2' 'EXCRA2' 'EXCRM2'\n",
      " 'EXCUT2' 'EXDEF2' 'EXDIA2' 'EXFEL2' 'EXGAU2' 'EXGN12' 'EXGN22' 'EXIHW2'\n",
      " 'EXIR_2' 'EXIRP2' 'EXISW2' 'EXKNA2' 'EXLAP2' 'EXMAN2' 'EXMLR2' 'EXMLT2'\n",
      " 'EXOHW2' 'EXOSW2' 'EXPAR2' 'EXPUS2' 'EXREJ2' 'EXREL2' 'EXSC_2' 'EXSCA2'\n",
      " 'EXSCM2' 'EXSH12' 'EXSH22' 'EXSHJ2' 'EXSHT2' 'EXSML2' 'EXSR_2' 'EXSRC2'\n",
      " 'EXSRE2' 'EXSSC2' 'EXSSR2' 'EXSTR2' 'EXTB_2' 'EXTB12' 'EXTB22' 'EXTTB2'\n",
      " 'EXTUC2' 'EXWIP2' 'MESY_2' 'MONIM2' 'MONIW2' 'SERV_2' 'VISU_2' 'WPS__2']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rack_cpu</th>\n",
       "      <th>chart</th>\n",
       "      <th>block</th>\n",
       "      <th>signal</th>\n",
       "      <th>value</th>\n",
       "      <th>link</th>\n",
       "      <th>type</th>\n",
       "      <th>out</th>\n",
       "      <th>rack</th>\n",
       "      <th>cpu</th>\n",
       "      <th>chartblock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TX04\\D01P01\\</td>\n",
       "      <td>ENCC_1</td>\n",
       "      <td>ABLOKD</td>\n",
       "      <td>I1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ENCC_1\\AND209.Q</td>\n",
       "      <td>BOOL</td>\n",
       "      <td>False</td>\n",
       "      <td>TX04</td>\n",
       "      <td>D01P01</td>\n",
       "      <td>ENCC_1/ABLOKD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TX04\\D01P01\\</td>\n",
       "      <td>ENCC_1</td>\n",
       "      <td>ABLOKD</td>\n",
       "      <td>I2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ENCC_1\\NOTBDW.Q</td>\n",
       "      <td>BOOL</td>\n",
       "      <td>False</td>\n",
       "      <td>TX04</td>\n",
       "      <td>D01P01</td>\n",
       "      <td>ENCC_1/ABLOKD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TX04\\D01P01\\</td>\n",
       "      <td>ENCC_1</td>\n",
       "      <td>ABLOKD</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "      <td>ENCC_1\\XN1030.I4</td>\n",
       "      <td>BOOL</td>\n",
       "      <td>True</td>\n",
       "      <td>TX04</td>\n",
       "      <td>D01P01</td>\n",
       "      <td>ENCC_1/ABLOKD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TX04\\D01P01\\</td>\n",
       "      <td>ENCC_1</td>\n",
       "      <td>ADD100</td>\n",
       "      <td>X1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ENCC_1\\DIV001.Y</td>\n",
       "      <td>REAL</td>\n",
       "      <td>False</td>\n",
       "      <td>TX04</td>\n",
       "      <td>D01P01</td>\n",
       "      <td>ENCC_1/ADD100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TX04\\D01P01\\</td>\n",
       "      <td>ENCC_1</td>\n",
       "      <td>ADD100</td>\n",
       "      <td>X2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ENCC_1\\CTB003.Y15</td>\n",
       "      <td>REAL</td>\n",
       "      <td>False</td>\n",
       "      <td>TX04</td>\n",
       "      <td>D01P01</td>\n",
       "      <td>ENCC_1/ADD100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rack_cpu   chart   block signal value               link  type    out  \\\n",
       "0  TX04\\D01P01\\  ENCC_1  ABLOKD     I1   NaN    ENCC_1\\AND209.Q  BOOL  False   \n",
       "1  TX04\\D01P01\\  ENCC_1  ABLOKD     I2   NaN    ENCC_1\\NOTBDW.Q  BOOL  False   \n",
       "2  TX04\\D01P01\\  ENCC_1  ABLOKD      Q     0   ENCC_1\\XN1030.I4  BOOL   True   \n",
       "3  TX04\\D01P01\\  ENCC_1  ADD100     X1   NaN    ENCC_1\\DIV001.Y  REAL  False   \n",
       "4  TX04\\D01P01\\  ENCC_1  ADD100     X2   NaN  ENCC_1\\CTB003.Y15  REAL  False   \n",
       "\n",
       "   rack     cpu     chartblock  \n",
       "0  TX04  D01P01  ENCC_1/ABLOKD  \n",
       "1  TX04  D01P01  ENCC_1/ABLOKD  \n",
       "2  TX04  D01P01  ENCC_1/ABLOKD  \n",
       "3  TX04  D01P01  ENCC_1/ADD100  \n",
       "4  TX04  D01P01  ENCC_1/ADD100  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load TDC data\n",
    "data_a1 = pd.read_csv(os.path.join(PATH_TO_DATA,FILE_NAME_DATA1),keep_default_na=False,na_values=[''], encoding=\"cp1251\",sep=';',header=None)\n",
    "data_a1 = data_a1[[0,1,3,5,11,13,28,29]]\n",
    "data_a1.columns = ['rack_cpu','chart','block','signal','value','link','type','out']\n",
    "data_a1 = pd.concat([data_a1, data_a1['rack_cpu'].str.split(\"\\\\\",expand = True)[[0,1]]], axis=1) \n",
    "data_a1.columns = ['rack_cpu','chart','block','signal','value','link','type','out','rack','cpu']\n",
    "data_a1[\"out\"]= data_a1[\"out\"].replace((\"IN\",\"OUT\"),(0,1)).astype('bool') \n",
    "data_a1 = data_a1[~data_a1['chart'].isin(IGNORE_CHART)]\n",
    "data_a1[\"block\"] = data_a1[\"block\"].astype(str)\n",
    "data_a1[\"chartblock\"] = data_a1[\"chart\"].str.upper()+\"/\"+data_a1[\"block\"].str.upper()\n",
    "print(\"Data types \",data_a1['type'].unique())\n",
    "print(\"Charts \",data_a1['chart'].unique())\n",
    "data_a1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Generate Simadyn chart structure\n",
    "def sd_get_chart_list(PATH_TO_STRUCG=PATH_TO_STRUCG,SD_RACK_NAMES=SD_RACK_NAMES):\n",
    "    #filter chart files\n",
    "    n = re.compile(\"^(((?!old).)*).((cfp)|(ofp))$\")\n",
    "    file_list=[] \n",
    "    file_list = {rack_name:[item for item in os.listdir(os.path.join(PATH_TO_STRUCG,rack_name)) \\\n",
    "        # chart file names filter conditions\n",
    "        if os.path.isfile(os.path.join(PATH_TO_STRUCG,rack_name, item)) and (n.search(item)) and len(item)<11 \\\n",
    "        ] for rack_name in SD_RACK_NAMES}\n",
    "    file_list_filtered = dict(file_list)\n",
    "    for i in file_list:\n",
    "        for k in file_list[i]:\n",
    "            chart_name = k.split('.')[0]\n",
    "            if \"%s.cfp\"%chart_name in file_list[i]:\n",
    "                try:\n",
    "                    file_list_filtered[i].remove(\"%s.ofp\"%chart_name)\n",
    "                except ValueError:\n",
    "                    pass  # do nothing\n",
    "    out_dict = dict()\n",
    "    for i in file_list_filtered:\n",
    "        out_dict[i] = dict()\n",
    "        for k in file_list_filtered[i]:\n",
    "            out_dict[i][k.split('.')[0]]=os.path.join(PATH_TO_STRUCG,i,k)\n",
    "    if out_dict:\n",
    "        return out_dict\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "#Generate Simadyn cpu mapping structure\n",
    "def sd_get_cpu_charts_list(PATH_TO_STRUCG=PATH_TO_STRUCG,SD_RACK_NAMES=SD_RACK_NAMES):\n",
    "    #filter chart files\n",
    "    n = re.compile(\"^((\\d+).*)\\.(mpn)$\")\n",
    "    file_list=[] \n",
    "    file_list=[] \n",
    "    file_list = {rack_name:[item for item in os.listdir(os.path.join(PATH_TO_STRUCG,rack_name)) \\\n",
    "        # chart file names filter conditions\n",
    "        if os.path.isfile(os.path.join(PATH_TO_STRUCG,rack_name, item)) and (n.search(item)) and len(item)<11 \\\n",
    "        ] for rack_name in SD_RACK_NAMES}\n",
    "    out_dict = dict()\n",
    "    for i in file_list:\n",
    "        out_dict[i] = dict()\n",
    "        for k in file_list[i]:\n",
    "            out_dict[i][k.split('.')[0]]=os.path.join(PATH_TO_STRUCG,i,k)\n",
    "    if out_dict:\n",
    "        return out_dict\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "sd_chart_list = sd_get_chart_list() \n",
    "sd_cpu_charts_list = sd_get_cpu_charts_list() \n",
    "\n",
    "##output => #sd_chart_list {\"tx03\":{'chrt_name':file_addrs}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tx04': {'1tx04': '/notebooks/pinda/data/test/tx04/1tx04.mpn',\n",
       "  '2tx04': '/notebooks/pinda/data/test/tx04/2tx04.mpn',\n",
       "  '3tx04': '/notebooks/pinda/data/test/tx04/3tx04.mpn'}}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 325\tI1  B1 < VIHW09.Q15&\n",
      "VIHW09.Q15\n",
      "  81\tIS  V2 < $VISW17\n",
      "$VISW17\n",
      " 163\tQ1  B1 > ,'Man__CPS'            \"MAINTENANCE COIL PREP STATION\"\n",
      "None\n",
      " 115\tI1  B1 < VIHW17.Q2&\n",
      "VIHW17.Q2\n",
      " 519\tX1  N2 < @TYP=V2,0HFFFF\n",
      "0HFFFF\n",
      " 520\tX2  N2 < @TYP=V2,LB2.QS&\n",
      "LB2.QS\n",
      " 527\tQS  V2 > $VGAU02                \"Diagnose 2nd direction\"\n",
      "$VGAU02\n",
      " 528\tQ   B1 > \n",
      "None\n",
      "  31\tAD  NK = D02_I1.X8C\n",
      "D02_I1.X8C\n",
      "  32\tDM  B1 - 1\n",
      "1\n",
      "  22\tAR  NS - 'B1G1X1'\n",
      "'B1G1X1'\n",
      "  21\tCTS CR - D0300A\n",
      "D0300A\n",
      "1151\tT1  NS - '@F@85@ EN QFC Coil P. Shear Tab. Air Float'\n",
      "'@F@85@ EN QFC Coil P. Shear Tab. Air Float'\n",
      "1199\tX1  N2 < 0%\n",
      "0%\n",
      "1200\tX2  N2 < SEND07.QS\n",
      "SEND07.QS\n",
      "1201\tI   B1 < EN_MES.Q,'EN_MES'&\n",
      "EN_MES.Q\n",
      " 566\tLZU NF < #10000[ms],'RunTime '  \"Run time monitoring\"\n",
      "#10000[ms]\n",
      "1207\tX2  N2 < 18.298%                \"18,3 representa 3000 kg\"\n",
      "18.298%\n",
      "1283\tX2  NF < #0\n",
      "#0\n",
      "1304\tX2  NF < #26,'GRAUS'\n",
      "#26\n",
      " 905\tX2  NF < #100.0000000E3\n",
      "#100.0000000E3\n",
      "1074\tY   NF > @TYP=TF,$PTTI_A,'PTTI_AUT'&\n",
      "$PTTI_A\n",
      "1073\tX   NF < @TYP=TF,10[S]\n",
      "10[S]\n",
      "2983\tX2  NF < #530.0000000E-3,'m'\n",
      "#530.0000000E-3\n",
      " 439\tFBU NF < #500[ms],'Feedback'    \"Feedback monitoring\"\n",
      "#500[ms]\n",
      " 494\tI   B1 < STG641.Q\n",
      "STG641.Q\n",
      " 495\tY   N2 > @TYP=V2\n",
      "None\n",
      "  17\tX1  NF < $XIHW05,SCAL=1[m]\n",
      "$XIHW05\n",
      " 374\tT   TF <  3           [s]\n",
      "3           [s]\n",
      " 169\tT   TF <            2[s ]\n",
      "2[s ]\n",
      "2946\tOR  V2 < 0B00000000 00000000\n",
      "0B00000000 00000000\n",
      " 108\tX05 NF < #2500.0[V/(m/s)],'ky'  \"Scaling factor for control output\"&\n",
      "#2500.0[V/(m/s)]\n",
      "2756\tCRT TR = !EXM504\n",
      "!EXM504\n",
      " 337\tQ1  B1 >\n",
      "None\n",
      "1407\tT   TF < #2.5 [s]\n",
      "#2.5 [s]\n",
      "  87\tQ3  B1 > $E_STOP PN,'E_STOP'&\n",
      "$E_STOP PN\n"
     ]
    }
   ],
   "source": [
    "#n = re.search(\"^(((?!old).)*).((cfp)|(ofp))$\", 'pray1___20131208.cfp')\n",
    "test_txt = []\n",
    "test_txt.append(\" 325\tI1  B1 < VIHW09.Q15&\")\n",
    "test_txt.append('  81\tIS  V2 < $VISW17')\n",
    "test_txt.append(\" 163\tQ1  B1 > ,'Man__CPS'            \\\"MAINTENANCE COIL PREP STATION\\\"\")\n",
    "test_txt.append(' 115\tI1  B1 < VIHW17.Q2&')\n",
    "test_txt.append(' 519\tX1  N2 < @TYP=V2,0HFFFF')\n",
    "test_txt.append(' 520\tX2  N2 < @TYP=V2,LB2.QS&')\n",
    "test_txt.append(' 527\tQS  V2 > $VGAU02                \"Diagnose 2nd direction\"')\n",
    "test_txt.append(' 528\tQ   B1 > ')\n",
    "test_txt.append(\"  31\tAD  NK = D02_I1.X8C\")\n",
    "test_txt.append(\"  32\tDM  B1 - 1\")\n",
    "test_txt.append(\"  22\tAR  NS - 'B1G1X1'\")\n",
    "test_txt.append(\"  21\tCTS CR - D0300A\")\n",
    "test_txt.append(\"1151\tT1  NS - '@F@85@ EN QFC Coil P. Shear Tab. Air Float'\")\n",
    "test_txt.append(\"1199\tX1  N2 < 0%\")\n",
    "test_txt.append(\"1200\tX2  N2 < SEND07.QS\")\n",
    "test_txt.append(\"1201\tI   B1 < EN_MES.Q,'EN_MES'&\")\n",
    "test_txt.append(\" 566\tLZU NF < #10000[ms],'RunTime '  \\\"Run time monitoring\\\"\")\n",
    "test_txt.append(\"1207\tX2  N2 < 18.298%                \\\"18,3 representa 3000 kg\\\"\")\n",
    "test_txt.append(\"1283\tX2  NF < #0\")\n",
    "test_txt.append(\"1304\tX2  NF < #26,'GRAUS'\")\n",
    "test_txt.append(\" 905\tX2  NF < #100.0000000E3\")\n",
    "test_txt.append(\"1074\tY   NF > @TYP=TF,$PTTI_A,'PTTI_AUT'&\")\n",
    "test_txt.append(\"1073\tX   NF < @TYP=TF,10[S]\")\n",
    "test_txt.append(\"2983\tX2  NF < #530.0000000E-3,'m'\")\n",
    "test_txt.append(\" 439\tFBU NF < #500[ms],'Feedback'    \\\"Feedback monitoring\\\"\")\n",
    "test_txt.append(\" 494\tI   B1 < STG641.Q\")\n",
    "test_txt.append(\" 495\tY   N2 > @TYP=V2\")\n",
    "test_txt.append(\"  17\tX1  NF < $XIHW05,SCAL=1[m]\")\n",
    "test_txt.append(\" 374\tT   TF <  3           [s]\")\n",
    "test_txt.append(\" 169\tT   TF <            2[s ]\")\n",
    "test_txt.append(\"2946\tOR  V2 < 0B00000000 00000000\")\n",
    "test_txt.append(\" 108\tX05 NF < #2500.0[V/(m/s)],'ky'  \\\"Scaling factor for control output\\\"&\")\n",
    "test_txt.append(\"2756\tCRT TR = !EXM504\")\n",
    "test_txt.append(\" 337\tQ1  B1 >\")\n",
    "test_txt.append(\"1407\tT   TF < #2.5 [s]\")\n",
    "test_txt.append(\"  87\tQ3  B1 > $E_STOP PN,'E_STOP'&\")\n",
    "\n",
    "test_txt2 = \" 439\tFBU NF < #500[ms],'Feedback'    \\\"Feedback monitoring\\\"\"\n",
    "\n",
    "\n",
    "#m = re.compile(r\"^\\s*\\d+\\s+(\\w+)\\s+(\\w+)\\s+([<>])\\s+(@TYP=(..),)?([^@\\\"',&]+)([,\\\"'&]|$)\", )\n",
    "m = re.compile(r\"\"\"\n",
    "        ^\\s*\\d+\\s+ #string number\n",
    "        (\\w+)\\s+   #signal name \n",
    "        (\\w+)\\s+   #signal type \n",
    "        ([<>=-])\\s*  #signal delimiter \n",
    "        (@TYP=(..),?)? #singal type\n",
    "        (   #value\n",
    "        ([a-zA-Z0-9_.]+)|  #can be connection to other block\n",
    "        ([$%!\\[\\]/()a-zA-Z0-9_.#-]+)|  #can be value\n",
    "        ([$a-zA-Z0-9_]+\\s*[$a-zA-Z0-9_]*)|  #can be virtual connection\n",
    "        ([#0-9.]+\\s*\\[.*\\])|  #can be time with spaces\n",
    "        ([0-9B]+\\s+[0-9]+)|  #can be hex in bit representation\n",
    "        ('.*') #can be text\n",
    "        )? #end of value\n",
    "        (,)? #divider\n",
    "        ('.*')? #link comment\n",
    "        (,.*)? #some comment\n",
    "        (\\s+\".*\")? #signal comment\n",
    "        (&)? #check next string\n",
    "        ($) #end of string\n",
    "        \"\"\", re.X)\n",
    "k = re.compile(r\"^\\s*\\d+\\s+(\\w+)\\s+(\\w+)\\s+([<>=-])\")\n",
    "\n",
    "for a in test_txt:\n",
    "    n = m.search(a)\n",
    "    print(a)\n",
    "    #print(n.group(1),n.group(2),n.group(3),n.group(5),n.group(6),n.group(13))\n",
    "    print(n.group(6))\n",
    "    #print(n)\n",
    "    \n",
    "#n = m.search(test_txt2)\n",
    "#print(\"OUT:\",n.group(1),n.group(2),n.group(3),n.group(6),n.group(13))\n",
    "\n",
    "#for a in test_txt:\n",
    "#    n = k.search(a)\n",
    "#    print(n)\n",
    "\n",
    "#for a in test_txt:\n",
    "#    n = k.search(a)\n",
    "#    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object; span=(0, 37), match='1679\\t   $VINS02 T4 < PN     PN-D01_P1'>\n",
      "$VINS02 < PN-D01_P1\n"
     ]
    }
   ],
   "source": [
    "#test_txt=\"   &\tV4.2.6 FP-COP CHK 22.02.;9 07:54  (MP-TX04.PN-D05_P2 13.09.;6 05:02)\"\n",
    "#test_txt = \"   1 PN-D01_P1\"\n",
    "#test_txt = \"1832\t*\"\n",
    "#test_txt = \"\"\n",
    "#test_txt = \"  89 Connector list of the function packets\"\n",
    "#test_txt = \"1816\tFP-@SEND1,COM\"\n",
    "test_txt = \"1679\t   $VINS02 T4 < PN     PN-D01_P1\"\n",
    "\n",
    "#cp = re.compile(r'^\\s+\\d+\\s+([a-zA-Z0-9_-]+)$')\n",
    "#cp = re.compile(r'^\\s+\\d+\\s+Connector list of the function packets')\n",
    "#cp = re.compile(r'^\\s*\\d+\\s+\\*')\n",
    "#cp = re.compile(r'^\\s*\\d+\\s+FP-([a-zA-Z0-9_\\-@]+)')\n",
    "cp = re.compile(r'^\\s*\\d+\\s+(\\$[a-zA-Z0-9_\\-@]+)\\s([\\w]+)\\s((<)|(>))\\s([\\w]+)\\s+([a-zA-Z0-9_-]+)$')\n",
    "cp_s = cp.search(test_txt)\n",
    "print(cp_s)\n",
    "print(cp_s.group(1),cp_s.group(3),cp_s.group(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEND01.I9\n",
      "KA1014.I2,KA1015.I2\n"
     ]
    }
   ],
   "source": [
    "test_txt = []\n",
    "test_txt.append(\"   &\t\t(SEND01.I9)\")\n",
    "test_txt.append('   &\t\t(KA1014.I2,KA1015.I2)')\n",
    "k = re.compile(r\"^\\s*&+\\s+\\((.*)\\)\\s*$\")\n",
    "for a in test_txt:\n",
    "    n = k.search(a)\n",
    "    print(n.group(1))\n",
    "    #print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################row data generating library#################\n",
    "\n",
    "#open chart for reading\n",
    "def sd_open_chart(chart_addr):\n",
    "    try:\n",
    "        with open(chart_addr) as f:\n",
    "            lines = [line.rstrip('\\n') for line in f]\n",
    "    except EnvironmentError: # parent of IOError, OSError *and* WindowsError where available\n",
    "        #print('ERROR File not exists!')\n",
    "        return -1\n",
    "    return lines\n",
    "\n",
    "#generate chart mapping: line {block name:[block line begin, block line end]}\n",
    "def sd_get_chart_map(inp_line):\n",
    "    b = re.compile(r\"^\\s*\\d+ ?([a-zA-Z0-9_]+) +: [a-zA-Z0-9_.@]+\\s*,\\s*POS=\")\n",
    "    el = re.compile(r'^ *\\d+\\s+[+]')\n",
    "    #cp = re.compile(r'\\(([a-zA-Z0-9_-]+).([a-zA-Z0-9_-]+)\\s+\\S+\\s+\\S+\\)') #not used, because not all charts consist\n",
    "    block_list = []\n",
    "    mark_bloc = False\n",
    "    #mark_cpu = False\n",
    "    out_dict = dict()\n",
    "    line_counter = 0\n",
    "    for k in inp_line:\n",
    "        #Find rack name and cpu name, e.g. MP-TX04 PN-D05_P2\n",
    "        #if not mark_cpu:\n",
    "        #    cp_s = cp.search(k)\n",
    "        #    if cp_s :\n",
    "        #        rack,cpu = cp_s.group(1),cp_s.group(2)\n",
    "        #        mark_cpu = True\n",
    "        b_s = b.search(k)\n",
    "        if b_s :\n",
    "            mark_bloc = True\n",
    "            curr_block_name = b_s.group(1)\n",
    "            block_list.append(curr_block_name)\n",
    "            mark_bloc_line_beg = line_counter\n",
    "        elif el.search(k):\n",
    "            if mark_bloc:\n",
    "                mark_bloc = False\n",
    "                out_dict[curr_block_name] = [mark_bloc_line_beg,line_counter]\n",
    "        line_counter = line_counter+1        \n",
    "    #print(len(block_list))\n",
    "    if(out_dict):\n",
    "        return out_dict\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "#check if line is signal or link\n",
    "def sd_check_line_signal(line):\n",
    "    sf = re.compile(r\"^\\s*\\d+\\s+(\\w+)\\s+(\\w+)\\s+([<>=-])\")\n",
    "    sa = re.compile(r\"^\\s*&+\\s+(\\(.*\\))\\s*$\")\n",
    "    if sf.search(line):\n",
    "        out = 1 #signal\n",
    "    elif sa.search(line):\n",
    "        out = 2 #link\n",
    "    else:\n",
    "        out = 0 #nothing\n",
    "    return out\n",
    "\n",
    "#extract data from signal line\n",
    "def sd_get_line_data(line): \n",
    "    m = re.compile(r\"\"\"\n",
    "        ^\\s*\\d+\\s+ #string number\n",
    "        (\\w+)\\s+   #signal name \n",
    "        (\\w+)\\s+   #signal type \n",
    "        ([<>=-])\\s*  #signal delimiter \n",
    "        (@TYP=(..),?)? #singal type\n",
    "        (   #value\n",
    "        ([a-zA-Z0-9_.]+)|  #can be connection to other block\n",
    "        ([$%!\\[\\]/()a-zA-Z0-9_.#-]+)|  #can be value\n",
    "        ([$a-zA-Z0-9_]+\\s*[$a-zA-Z0-9_]*)|  #can be virtual connection\n",
    "        ([#0-9.]+\\s*\\[.*\\])|  #can be time with spaces\n",
    "        ([0-9B]+\\s+[0-9]+)|  #can be hex in bit representation\n",
    "        ('.*') #can be text\n",
    "        )? #end of value\n",
    "        (,)? #divider\n",
    "        ('.*')? #link comment\n",
    "        (,.*)? #some comment\n",
    "        (\\s+\".*\")? #signal comment\n",
    "        (&)? #check next string\n",
    "        ($) #end of string\n",
    "        \"\"\", re.X)\n",
    "    #print(line)\n",
    "    n = m.search(line)\n",
    "    try: \n",
    "        out = list([n.group(1),n.group(2),n.group(3),n.group(5),n.group(6)])\n",
    "    except:\n",
    "        print(line)\n",
    "        raise\n",
    "        \n",
    "                 #name      type       dir        type_conv  value      \n",
    "    return list([n.group(1),n.group(2),n.group(3),n.group(5),n.group(6)])\n",
    "\n",
    "#exstract link from like\n",
    "def sd_get_line_link(line): \n",
    "    m = re.compile(r\"^\\s*&+\\s+\\((.*)\\)\\s*$\")\n",
    "    n = m.search(line)     \n",
    "    return n.group(1)  \n",
    "\n",
    "#get block data: signals, values, links, data types...\n",
    "def sd_get_block_data(lines):\n",
    "    NAME,TYPE_BASE,INOUT,TYPE_CONV,VALUE = 0,1,2,3,4\n",
    "    mark_signal_row_name = None\n",
    "    mark_signal_row_data = list([[],[]]) #[[signal data],[links]]\n",
    "    mark_block_row_data = []\n",
    "    count = 0;\n",
    "    for l in lines:\n",
    "        line_check_result = sd_check_line_signal(l)\n",
    "        if line_check_result:\n",
    "            if line_check_result==1:  \n",
    "                #if found a signal line\n",
    "                count = count+1\n",
    "                #add previous signal to preparation table\n",
    "                if mark_signal_row_name:\n",
    "                    #print(\"Old name:\",mark_signal_row_name)\n",
    "                    mark_block_row_data.append(mark_signal_row_data)\n",
    "                    mark_signal_row_data = list([[],[]]) #reset buffer table\n",
    "                #name,type,dir,type_conv,more\n",
    "                mark_signal_row_data[0] = sd_get_line_data(l)\n",
    "                mark_signal_row_name = mark_signal_row_data[0][NAME]\n",
    "                #print(mark_signal_row_name)\n",
    "            elif line_check_result==2:\n",
    "                #if found a link line\n",
    "                mark_signal_row_data[1].extend(sd_get_line_link(l).split(','))\n",
    "            #print(mark_signal_row_data)            \n",
    "        else:\n",
    "            pass #skip string\n",
    "    #Add last signal to preparation storage\n",
    "    mark_block_row_data.append(mark_signal_row_data)\n",
    "    return mark_block_row_data\n",
    "\n",
    "#convert list to pandas data frame\n",
    "def sd_conv_block_data_to_df(block_data):\n",
    "    #list element of row signal data:[[NAME,TYPE_BASE,INOUT,TYPE_CONV,VALUE],[links]]\n",
    "    block_df = pd.DataFrame([[j for j in k[0]]+[k[1]] for k in block_data])\n",
    "    return block_df\n",
    "#convert list to better representation\n",
    "def sd_conv_block_data_to_list(block_data):\n",
    "    #list element of row signal data:[[NAME,TYPE_BASE,INOUT,TYPE_CONV,VALUE],[links]]\n",
    "    block_list = [[j for j in k[0]]+[k[1]] for k in block_data]\n",
    "    return block_list\n",
    "\n",
    "\n",
    "#create df row with link source structure: chart_block_signal,cpu_link\n",
    "def sd_get_source_link(block_data_df):\n",
    "    m = re.compile(r\"^\\$\\w+\")\n",
    "    out_df = []\n",
    "    for i, j in block_data_df.iterrows():\n",
    "        if j[2]==\">\":\n",
    "            #look for source link in value field\n",
    "            if(j[4]):\n",
    "                n = m.search(j[4]) \n",
    "                if n:\n",
    "                    chart_block_signal = j[6].upper()+'/'+j[7].upper()+'.'+j[0].upper()\n",
    "                    cpu_link = j[8]+'_'+j[4]\n",
    "                    #print(chart_block_signal,\"=>\",cpu_link)\n",
    "                    out_df.append([chart_block_signal,cpu_link])\n",
    "            #look for source link in link field\n",
    "            for k in j[5]:\n",
    "                if(k):\n",
    "                    n = m.search(k) \n",
    "                    if n:\n",
    "                        chart_block_signal = j[6].upper()+'/'+j[7].upper()+'.'+j[0].upper()\n",
    "                        cpu_link = j[8]+'_'+k\n",
    "                        #print(chart_block_signal,\"=>\",cpu_link)\n",
    "                        out_df.append([chart_block_signal,cpu_link])\n",
    "    return out_df\n",
    "\n",
    "#generate data of all charts and generate data of link sources\n",
    "def sd_build_data_s1(sd_chart_list,data_link_map_df):\n",
    "    data_df = pd.DataFrame(None, index=[], columns=range(8))\n",
    "    data_list = []\n",
    "    data_link_source_df = pd.DataFrame(None, index=[], columns=['chart_block_signal','cpu_link'])\n",
    "    for i in sd_chart_list:\n",
    "        for (k,v) in sd_chart_list[i].items(): \n",
    "            chart = k.upper()\n",
    "            chart_lines = sd_open_chart(v)\n",
    "            chart_mapping = sd_get_chart_map(chart_lines)\n",
    "            print(\"Parsing '%s' chart with %s functions\"%(chart,len(chart_mapping)))\n",
    "            for block_map in chart_mapping:\n",
    "                #print(block_map,chart_mapping[block_map])\n",
    "                block_lines = chart_lines[chart_mapping[block_map][0]:chart_mapping[block_map][1]]\n",
    "                block_data = sd_get_block_data(block_lines)\n",
    "                ##block_data_df = sd_conv_block_data_to_df(block_data)\n",
    "                block_data_list = sd_conv_block_data_to_list(block_data)\n",
    "                #add chart name\n",
    "                ##block_data_df[6] = chart\n",
    "                block_data_list.append(chart)\n",
    "                #add block name\n",
    "                ##block_data_df[7] = block_map\n",
    "                block_data_list.append(block_map)\n",
    "                ##block_data_df[8] = sd_get_chart_cpu(data_link_map_df,chart)\n",
    "                block_data_list.append(sd_get_chart_cpu)\n",
    "                #append block array to full array\n",
    "                ##data_df = data_df.append(block_data_df, ignore_index = True) \n",
    "                data_list = \n",
    "                #create link source array\n",
    "                block_link_source_arr = sd_get_source_link(block_data_df)\n",
    "                if len(block_link_source_arr)!=0:\n",
    "                    data_link_source_df = data_link_source_df.append(block_link_source_arr, ignore_index = True) \n",
    "                    \n",
    "    return data_df,data_link_source_df\n",
    "\n",
    "#generate cpu,link db by cpu mapping file\n",
    "def sd_build_cpu_map(sd_chart_list):\n",
    "    data_link_map_list = []\n",
    "    cp = re.compile(r'^\\s+\\d+\\s+([a-zA-Z0-9_-]+)$') #find CPU name in file\n",
    "    bg = re.compile(r'^\\s+\\d+\\s+Connector list of the function packets') # find beginning of link information\n",
    "    en = re.compile(r'^\\s*\\d+\\s+\\*')\n",
    "    ch = re.compile(r'^\\s*\\d+\\s+FP-([a-zA-Z0-9_\\-@]+)')\n",
    "    lk = re.compile(r'^\\s*\\d+\\s+(\\$[a-zA-Z0-9_\\-@]+)\\s([\\w]+)\\s((<)|(>))\\s([\\w]+)\\s+([a-zA-Z0-9_-]+)$')\n",
    "    \n",
    "    for i in sd_chart_list:\n",
    "        for (k,v) in sd_chart_list[i].items():\n",
    "            chart_lines = sd_open_chart(v)\n",
    "            print(\"Parsing '%s' chart \"%(k))\n",
    "            cpu_mark = False\n",
    "            beg_mark = False\n",
    "            end_mark = False\n",
    "            for l in chart_lines:\n",
    "                ##Find CPU name\n",
    "                if not cpu_mark:\n",
    "                    cp_s = cp.search(l)\n",
    "                    if cp_s :\n",
    "                        cpu = cp_s.group(1)\n",
    "                        cpu_mark = True\n",
    "                        print(cpu)   \n",
    "                else:\n",
    "                    if not beg_mark:\n",
    "                        if bg.search(l):\n",
    "                            beg_mark = True\n",
    "                    else:\n",
    "                        #check end\n",
    "                        if en.search(l):\n",
    "                            end_mark = True\n",
    "                            break\n",
    "                        else:\n",
    "                            #main block:\n",
    "                            ch_s = ch.search(l)\n",
    "                            if ch.search(l): #if chart beginning 1739\tFP-MONIW1\n",
    "                                chart = ch_s.group(1)\n",
    "                            else:\n",
    "                                lk_s = lk.search(l)\n",
    "                                if lk_s: #if chart link definition 1744\t   $DMALB1 T5 < PN     PN-D01_P1\n",
    "                                    #'cpu','chart','out','link','cpu_source'\n",
    "                                    data_link_map_list.append([cpu, chart.upper(),lk_s.group(3),lk_s.group(1),lk_s.group(7)])\n",
    "    data_link_map_df = pd.DataFrame(data_link_map_list, columns=['cpu','chart','out','link','cpu_source'])\n",
    "    return data_link_map_df\n",
    "\n",
    "def sd_get_chart_cpu(data_link_map_df,chart):\n",
    "    return data_link_map_df[data_link_map_df['chart']==chart].iloc[0]['cpu']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing '1tx04' chart \n",
      "PN-D01_P1\n",
      "Parsing '2tx04' chart \n",
      "PN-D05_P2\n",
      "Parsing '3tx04' chart \n",
      "PN-D08_P3\n",
      "Parsing 'ENBRI1' chart with 70 functions\n",
      "Parsing 'ENBRU1' chart with 81 functions\n",
      "Parsing 'ENCC_1' chart with 586 functions\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-327-b73320554d9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata_lm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msd_build_cpu_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msd_cpu_charts_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdata_s1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_ls1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msd_build_data_s1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msd_chart_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_lm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdata_s1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'signal'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'type_base'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'inout'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'type_conv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'link'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'chart'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'block'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdata_s1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"block\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_s1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"block\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-326-b3bb7e7ad623>\u001b[0m in \u001b[0;36msd_build_data_s1\u001b[0;34m(sd_chart_list, data_link_map_df)\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0mblock_data_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msd_get_chart_cpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_link_map_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m#append block array to full array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m                 \u001b[0mdata_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_data_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m                 \u001b[0;31m#create link source array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0mblock_link_source_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msd_get_source_link\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_data_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[1;32m   6690\u001b[0m         return concat(to_concat, ignore_index=ignore_index,\n\u001b[1;32m   6691\u001b[0m                       \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6692\u001b[0;31m                       sort=sort)\n\u001b[0m\u001b[1;32m   6693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6694\u001b[0m     def join(self, other, on=None, how='left', lsuffix='', rsuffix='',\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    227\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                        copy=copy, sort=sort)\n\u001b[0;32m--> 229\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    424\u001b[0m             new_data = concatenate_block_managers(\n\u001b[1;32m    425\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m                 copy=self.copy)\n\u001b[0m\u001b[1;32m    427\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0mnew_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m   2054\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_block_same_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2056\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mis_uniform_join_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2057\u001b[0m             b = join_units[0].block.concat_same_type(\n\u001b[1;32m   2058\u001b[0m                 [ju.block for ju in join_units], placement=placement)\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36mis_uniform_join_units\u001b[0;34m(join_units)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;31m# no blocks that would get missing values (can lead to type upcasts)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;31m# unless we're an extension dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mju\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_na\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mju\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_extension\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mju\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjoin_units\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m         \u001b[0;31m# no blocks with indexers (as then the dimensions do not fit)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mju\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexers\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mju\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjoin_units\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;31m# no blocks that would get missing values (can lead to type upcasts)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;31m# unless we're an extension dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mju\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_na\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mju\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_extension\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mju\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjoin_units\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m         \u001b[0;31m# no blocks with indexers (as then the dimensions do not fit)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mju\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexers\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mju\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjoin_units\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36mis_na\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mchunk_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_len\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues_flat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mchunk_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/dtypes/missing.py\u001b[0m in \u001b[0;36misna\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mName\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \"\"\"\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_isna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/dtypes/missing.py\u001b[0m in \u001b[0;36m_isna_new\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    112\u001b[0m                           \u001b[0mABCExtensionArray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                           ABCDatetimeArray, ABCTimedeltaArray)):\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_isna_ndarraylike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCGeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/dtypes/missing.py\u001b[0m in \u001b[0;36m_isna_ndarraylike\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mis_string_like_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m             \u001b[0;31m# object array of strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_string_like_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1541\u001b[0m     return _is_dtype(\n\u001b[0;32m-> 1542\u001b[0;31m         arr_or_dtype, lambda dtype: dtype.kind in ('S', 'U'))\n\u001b[0m\u001b[1;32m   1543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36m_is_dtype\u001b[0;34m(arr_or_dtype, condition)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnicodeEncodeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1805\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1806\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m   1540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1541\u001b[0m     return _is_dtype(\n\u001b[0;32m-> 1542\u001b[0;31m         arr_or_dtype, lambda dtype: dtype.kind in ('S', 'U'))\n\u001b[0m\u001b[1;32m   1543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#execution cell\n",
    "#creating row data DataFrame \"data_s1\" from chart list\n",
    "        \n",
    "data_lm = sd_build_cpu_map(sd_cpu_charts_list)\n",
    "data_s1,data_ls1 = sd_build_data_s1(sd_chart_list,data_lm)\n",
    "data_s1.columns = ['signal','type_base','inout','type_conv','value','link','chart','block','cpu']\n",
    "data_s1[\"block\"] = data_s1[\"block\"].astype(str)\n",
    "\n",
    "#save intermidiate result\n",
    "#data_s1.to_csv(os.path.join(PATH_TO_DATA,FILE_NAME_TEMP1))\n",
    "\n",
    "data_ls1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#restore intermediate result\n",
    "data_s1 = pd.read_csv(os.path.join(PATH_TO_DATA,FILE_NAME_TEMP1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rectify function: move Links \"AAA.AA\" of inputs to row \"link\"\n",
    "def sd_rect_data_s1(data_df):\n",
    "    def filter_func_output(x):\n",
    "        if(re.search(r'(\\S+[.]\\D+)',str(x[4]))):\n",
    "            x[5]=[x[4]]\n",
    "        return x\n",
    "    return data_df.apply(filter_func_output, axis = 1)\n",
    "\n",
    "#rectify function: add block \"chartblock\"\n",
    "def sd_rect_data_s2(data_df):\n",
    "    data_df['chartblock'] = data_df[\"chart\"].str.upper()+\"/\"+data_df[\"block\"].str.upper()\n",
    "    return data_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_s1 = sd_rect_data_s1(data_s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_s2 = sd_rect_data_s2(data_s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>signal</th>\n",
       "      <th>type_base</th>\n",
       "      <th>inout</th>\n",
       "      <th>type_conv</th>\n",
       "      <th>value</th>\n",
       "      <th>link</th>\n",
       "      <th>chart</th>\n",
       "      <th>block</th>\n",
       "      <th>chartblock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71787</th>\n",
       "      <td>71787</td>\n",
       "      <td>Q3</td>\n",
       "      <td>B1</td>\n",
       "      <td>&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$E_STOP PN</td>\n",
       "      <td>[]</td>\n",
       "      <td>enihw1</td>\n",
       "      <td>BII001</td>\n",
       "      <td>ENIHW1/BII001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101304</th>\n",
       "      <td>101304</td>\n",
       "      <td>CDM</td>\n",
       "      <td>B1</td>\n",
       "      <td>&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$BCSCDM PN</td>\n",
       "      <td>[]</td>\n",
       "      <td>@send1</td>\n",
       "      <td>CS22</td>\n",
       "      <td>@SEND1/CS22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0 signal type_base inout type_conv       value link   chart  \\\n",
       "71787        71787     Q3        B1     >       NaN  $E_STOP PN   []  enihw1   \n",
       "101304      101304    CDM        B1     >       NaN  $BCSCDM PN   []  @send1   \n",
       "\n",
       "         block     chartblock  \n",
       "71787   BII001  ENIHW1/BII001  \n",
       "101304    CS22    @SEND1/CS22  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = data_s2.copy()\n",
    "test_df[test_df['value'].apply(lambda x: bool(re.search(r\"\\$\\w+\\s+\\w+\",str(x)))==True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#report generator of comparison of block in all SD and TDC charts\n",
    "def report_find_miss_blocks (data_sd,data_tdc, to_file = True, timestamp = datetime.datetime.now()):\n",
    "    README_HEADER = COMPARATOR_README +\"\\\n",
    "\\r\\nReport: find missing blocks in TDC program\\\n",
    "\\r\\nDate ant time of report generation: %s \\\n",
    "\\r\\n===================================================================================\\\n",
    "\\r\\n\"%(str(timestamp))\n",
    "    \n",
    "    def generate_report(f):\n",
    "        print(README_HEADER,file = f) \n",
    "        sd_uniq_blocks = data_sd['chartblock'].unique()\n",
    "        tdc_uniq_blocks = data_tdc['chartblock'].unique()\n",
    "        for i in sd_uniq_blocks:\n",
    "            if not i in tdc_uniq_blocks:\n",
    "                print(\"Missing block in TDC: \",i,\"\\r\\n\",file = f) \n",
    "        \n",
    "        \n",
    "        \n",
    "    if to_file:\n",
    "        file_suffix = \"_find_miss_blocks_sd\"\n",
    "        file_prefix = \"report_\"\n",
    "        try:\n",
    "            # Create target Directory\n",
    "            os.mkdir(os.path.join(PATH_TO_REPORTS))\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        #sys.stdout = open(os.path.join(PATH_TO_REPORTS,(file_prefix+FILE_NAME_DATA1.split(\".\")[0]+file_suffix+\".txt\")), 'w')\n",
    "        with open(os.path.join(PATH_TO_REPORTS,(file_prefix+FILE_NAME_DATA1.split(\".\")[0]+file_suffix+\".txt\")), 'w') as f: \n",
    "            generate_report(f)\n",
    "    else:\n",
    "        generate_report(sys.stdout)\n",
    "\n",
    "        #data_a1_1 = data_a1\n",
    "        #for i, j in data_a1_1.iterrows():\n",
    "        #    if(not j['out']) and not pd.isnull(j['value']):\n",
    "\n",
    "    \n",
    "    \n",
    "#test_df = data_s2.head(5000).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#############EXECUTION GENERATE REPORT report_find_miss_blocks############\n",
    "report_find_miss_blocks(data_s2,data_a1,to_file = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
