{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.6.7\n",
      "IPython 7.4.0\n",
      "\n",
      "numpy 1.16.2\n",
      "scipy 1.2.1\n",
      "pandas 0.24.2\n",
      "matplotlib 3.0.3\n",
      "sklearn 0.20.3\n",
      "\n",
      "compiler   : GCC 8.2.0\n",
      "system     : Linux\n",
      "release    : 4.9.93-boot2docker\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 2\n",
      "interpreter: 64bit\n",
      "Git hash   :\n"
     ]
    }
   ],
   "source": [
    "# pip install watermark\n",
    "%load_ext watermark\n",
    "%watermark -v -m -p numpy,scipy,pandas,matplotlib,sklearn -g \n",
    "#,statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import datetime\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================================================\r\n",
      "Advanced comparator SimadynD <=> TDC software version: v.11 \r\n",
      "Author: Anton Tushev \r\n",
      "Comparison result made from /notebooks/pinda/data/test StrucG folder \r\n",
      "TDC data file is 'TX04_fixed_v1.csv' \r\n",
      "List of SimadynD subfolders for parsing is ['tx04'] \r\n",
      "List of ignored charts is ['@SIMD'] \r\n",
      "===================================================================================\n"
     ]
    }
   ],
   "source": [
    "COMPARATOR_AUTHOR = \"Anton Tushev\" \n",
    "COMPARATOR_VERSION = \"v.11\"\n",
    "PATH_TO_DATA = '/notebooks/pinda/data'\n",
    "#PATH_TO_STRUCG = '/notebooks/pinda/data/alcanc26_03_2019'\n",
    "PATH_TO_STRUCG = '/notebooks/pinda/data/test'\n",
    "PATH_TO_REPORTS = '/notebooks/pinda/reports'\n",
    "FILE_NAME_DATA1 = 'TX04_fixed_v1.csv'\n",
    "SD_RACK_NAMES = ['tx04']\n",
    "FILE_NAME_TEMP1 = 'TX04_@progress_bkup.csv'\n",
    "#FILE_NAME_DATA1 = 'test.csv'\n",
    "IGNORE_CHART = ['@SIMD']\n",
    "SKIP_EQUAL = True\n",
    "SKIP_BLOCK_NEXST = True\n",
    "SKIP_SIGNAL_NFND = True\n",
    "SKIP_TYPE_STR = True\n",
    "SKIP_CHART_NFND = True\n",
    "COMPARATOR_README = \"===================================================================================\\\n",
    "\\r\\nAdvanced comparator SimadynD <=> TDC software version: %s \\r\\nAuthor: %s \\\n",
    "\\r\\nComparison result made from %s StrucG folder \\\n",
    "\\r\\nTDC data file is '%s' \\\n",
    "\\r\\nList of SimadynD subfolders for parsing is %s \\\n",
    "\\r\\nList of ignored charts is %s \\\n",
    "\\r\\n===================================================================================\\\n",
    "\"%(COMPARATOR_VERSION,COMPARATOR_AUTHOR,PATH_TO_STRUCG,FILE_NAME_DATA1,SD_RACK_NAMES,IGNORE_CHART)\n",
    "print(COMPARATOR_README)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types  ['BOOL' 'REAL' 'SDTIME' 'WORD' 'INT' 'DINT' 'GLOBAL' 'STRING' 'DWORD'\n",
      " 'BYTE']\n",
      "Charts  ['ENCC_1' 'ENBRU1' 'ENBRI1' 'ENBEA1' 'BGT__1' '@SEND1' 'ENGAU1' 'ENGN11'\n",
      " 'ENMB_1' 'ENOSW1' 'ENGUA1' 'ENHDR1' 'ENIHW1' 'ENINS1' 'ENEXT1' 'ENENT1'\n",
      " 'ENSR_1' 'ENSPH1' 'ENSCD1' 'ENPIN1' 'ENPEL1' 'ENPAR1' 'ENISW1' 'ENLAP1'\n",
      " 'ENMA_1' 'ENMAN1' 'ENOHW1' 'ENSTR1' 'ENTEM1' 'ENTUR1' 'MESY_1' 'MONIM1'\n",
      " 'MONIW1' 'SERV_1' 'VISU_1' 'WPS__1' 'ENISW_MSU' 'ENDIA1' 'ENCRA1'\n",
      " 'ENCPT1' 'ENCPS1' 'ENCPP1' 'ENCPM1' 'ENCPH1' 'ENCPC1' 'ENCPA1' 'ENCOO1'\n",
      " 'ENMG_1' 'ENMC_1' 'ENMD_1' 'ENME_1' 'ENMF_1' '@SEND2' 'EXBAN2' 'EXBBH2'\n",
      " 'EXBBY2' 'EXBEA2' 'EXBW_2' 'EXBWA2' 'EXBWT2' 'EXCC_2' 'EXCRA2' 'EXCRM2'\n",
      " 'EXCUT2' 'EXDEF2' 'EXDIA2' 'EXFEL2' 'EXGAU2' 'EXGN12' 'EXGN22' 'EXIHW2'\n",
      " 'EXIR_2' 'EXIRP2' 'EXISW2' 'EXKNA2' 'EXLAP2' 'EXMAN2' 'EXMLR2' 'EXMLT2'\n",
      " 'EXOHW2' 'EXOSW2' 'EXPAR2' 'EXPUS2' 'EXREJ2' 'EXREL2' 'EXSC_2' 'EXSCA2'\n",
      " 'EXSCM2' 'EXSH12' 'EXSH22' 'EXSHJ2' 'EXSHT2' 'EXSML2' 'EXSR_2' 'EXSRC2'\n",
      " 'EXSRE2' 'EXSSC2' 'EXSSR2' 'EXSTR2' 'EXTB_2' 'EXTB12' 'EXTB22' 'EXTTB2'\n",
      " 'EXTUC2' 'EXWIP2' 'MESY_2' 'MONIM2' 'MONIW2' 'SERV_2' 'VISU_2' 'WPS__2']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rack_cpu</th>\n",
       "      <th>chart</th>\n",
       "      <th>block</th>\n",
       "      <th>signal</th>\n",
       "      <th>value</th>\n",
       "      <th>link</th>\n",
       "      <th>type</th>\n",
       "      <th>out</th>\n",
       "      <th>rack</th>\n",
       "      <th>cpu</th>\n",
       "      <th>chartblock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TX04\\D01P01\\</td>\n",
       "      <td>ENCC_1</td>\n",
       "      <td>ABLOKD</td>\n",
       "      <td>I1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ENCC_1\\AND209.Q</td>\n",
       "      <td>BOOL</td>\n",
       "      <td>False</td>\n",
       "      <td>TX04</td>\n",
       "      <td>D01P01</td>\n",
       "      <td>ENCC_1/ABLOKD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TX04\\D01P01\\</td>\n",
       "      <td>ENCC_1</td>\n",
       "      <td>ABLOKD</td>\n",
       "      <td>I2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ENCC_1\\NOTBDW.Q</td>\n",
       "      <td>BOOL</td>\n",
       "      <td>False</td>\n",
       "      <td>TX04</td>\n",
       "      <td>D01P01</td>\n",
       "      <td>ENCC_1/ABLOKD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TX04\\D01P01\\</td>\n",
       "      <td>ENCC_1</td>\n",
       "      <td>ABLOKD</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "      <td>ENCC_1\\XN1030.I4</td>\n",
       "      <td>BOOL</td>\n",
       "      <td>True</td>\n",
       "      <td>TX04</td>\n",
       "      <td>D01P01</td>\n",
       "      <td>ENCC_1/ABLOKD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TX04\\D01P01\\</td>\n",
       "      <td>ENCC_1</td>\n",
       "      <td>ADD100</td>\n",
       "      <td>X1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ENCC_1\\DIV001.Y</td>\n",
       "      <td>REAL</td>\n",
       "      <td>False</td>\n",
       "      <td>TX04</td>\n",
       "      <td>D01P01</td>\n",
       "      <td>ENCC_1/ADD100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TX04\\D01P01\\</td>\n",
       "      <td>ENCC_1</td>\n",
       "      <td>ADD100</td>\n",
       "      <td>X2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ENCC_1\\CTB003.Y15</td>\n",
       "      <td>REAL</td>\n",
       "      <td>False</td>\n",
       "      <td>TX04</td>\n",
       "      <td>D01P01</td>\n",
       "      <td>ENCC_1/ADD100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rack_cpu   chart   block signal value               link  type    out  \\\n",
       "0  TX04\\D01P01\\  ENCC_1  ABLOKD     I1   NaN    ENCC_1\\AND209.Q  BOOL  False   \n",
       "1  TX04\\D01P01\\  ENCC_1  ABLOKD     I2   NaN    ENCC_1\\NOTBDW.Q  BOOL  False   \n",
       "2  TX04\\D01P01\\  ENCC_1  ABLOKD      Q     0   ENCC_1\\XN1030.I4  BOOL   True   \n",
       "3  TX04\\D01P01\\  ENCC_1  ADD100     X1   NaN    ENCC_1\\DIV001.Y  REAL  False   \n",
       "4  TX04\\D01P01\\  ENCC_1  ADD100     X2   NaN  ENCC_1\\CTB003.Y15  REAL  False   \n",
       "\n",
       "   rack     cpu     chartblock  \n",
       "0  TX04  D01P01  ENCC_1/ABLOKD  \n",
       "1  TX04  D01P01  ENCC_1/ABLOKD  \n",
       "2  TX04  D01P01  ENCC_1/ABLOKD  \n",
       "3  TX04  D01P01  ENCC_1/ADD100  \n",
       "4  TX04  D01P01  ENCC_1/ADD100  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load TDC data\n",
    "data_a1 = pd.read_csv(os.path.join(PATH_TO_DATA,FILE_NAME_DATA1),keep_default_na=False,na_values=[''], encoding=\"cp1251\",sep=';',header=None)\n",
    "data_a1 = data_a1[[0,1,3,5,11,13,28,29]]\n",
    "data_a1.columns = ['rack_cpu','chart','block','signal','value','link','type','out']\n",
    "data_a1 = pd.concat([data_a1, data_a1['rack_cpu'].str.split(\"\\\\\",expand = True)[[0,1]]], axis=1) \n",
    "data_a1.columns = ['rack_cpu','chart','block','signal','value','link','type','out','rack','cpu']\n",
    "data_a1[\"out\"]= data_a1[\"out\"].replace((\"IN\",\"OUT\"),(0,1)).astype('bool') \n",
    "data_a1 = data_a1[~data_a1['chart'].isin(IGNORE_CHART)]\n",
    "data_a1[\"block\"] = data_a1[\"block\"].astype(str)\n",
    "data_a1[\"chartblock\"] = data_a1[\"chart\"].str.upper()+\"/\"+data_a1[\"block\"].str.upper()\n",
    "print(\"Data types \",data_a1['type'].unique())\n",
    "print(\"Charts \",data_a1['chart'].unique())\n",
    "data_a1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Generate Simadyn chart structure\n",
    "def sd_get_chart_list(PATH_TO_STRUCG=PATH_TO_STRUCG,SD_RACK_NAMES=SD_RACK_NAMES):\n",
    "    #filter chart files\n",
    "    n = re.compile(\"^(((?!old).)*).((cfp)|(ofp))$\")\n",
    "    file_list=[] \n",
    "    file_list = {rack_name:[item for item in os.listdir(os.path.join(PATH_TO_STRUCG,rack_name)) \\\n",
    "        # chart file names filter conditions\n",
    "        if os.path.isfile(os.path.join(PATH_TO_STRUCG,rack_name, item)) and (n.search(item)) and len(item)<11 \\\n",
    "        ] for rack_name in SD_RACK_NAMES}\n",
    "    file_list_filtered = dict(file_list)\n",
    "    for i in file_list:\n",
    "        for k in file_list[i]:\n",
    "            chart_name = k.split('.')[0]\n",
    "            if \"%s.cfp\"%chart_name in file_list[i]:\n",
    "                try:\n",
    "                    file_list_filtered[i].remove(\"%s.ofp\"%chart_name)\n",
    "                except ValueError:\n",
    "                    pass  # do nothing\n",
    "    out_dict = dict()\n",
    "    for i in file_list_filtered:\n",
    "        out_dict[i] = dict()\n",
    "        for k in file_list_filtered[i]:\n",
    "            out_dict[i][k.split('.')[0]]=os.path.join(PATH_TO_STRUCG,i,k)\n",
    "    if out_dict:\n",
    "        return out_dict\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "#Generate Simadyn cpu mapping structure\n",
    "def sd_get_cpu_charts_list(PATH_TO_STRUCG=PATH_TO_STRUCG,SD_RACK_NAMES=SD_RACK_NAMES):\n",
    "    #filter chart files\n",
    "    n = re.compile(\"^((\\d+).*)\\.(mpn)$\")\n",
    "    file_list=[] \n",
    "    file_list=[] \n",
    "    file_list = {rack_name:[item for item in os.listdir(os.path.join(PATH_TO_STRUCG,rack_name)) \\\n",
    "        # chart file names filter conditions\n",
    "        if os.path.isfile(os.path.join(PATH_TO_STRUCG,rack_name, item)) and (n.search(item)) and len(item)<11 \\\n",
    "        ] for rack_name in SD_RACK_NAMES}\n",
    "    out_dict = dict()\n",
    "    for i in file_list:\n",
    "        out_dict[i] = dict()\n",
    "        for k in file_list[i]:\n",
    "            out_dict[i][k.split('.')[0]]=os.path.join(PATH_TO_STRUCG,i,k)\n",
    "    if out_dict:\n",
    "        return out_dict\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "sd_chart_list = sd_get_chart_list() \n",
    "sd_cpu_charts_list = sd_get_cpu_charts_list() \n",
    "\n",
    "##output => #sd_chart_list {\"tx03\":{'chrt_name':file_addrs}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 325\tI1  B1 < VIHW09.Q15&\n",
      "VIHW09.Q15\n",
      "  81\tIS  V2 < $VISW17\n",
      "$VISW17\n",
      " 163\tQ1  B1 > ,'Man__CPS'            \"MAINTENANCE COIL PREP STATION\"\n",
      "None\n",
      " 115\tI1  B1 < VIHW17.Q2&\n",
      "VIHW17.Q2\n",
      " 519\tX1  N2 < @TYP=V2,0HFFFF\n",
      "0HFFFF\n",
      " 520\tX2  N2 < @TYP=V2,LB2.QS&\n",
      "LB2.QS\n",
      " 527\tQS  V2 > $VGAU02                \"Diagnose 2nd direction\"\n",
      "$VGAU02\n",
      " 528\tQ   B1 > \n",
      "None\n",
      "  31\tAD  NK = D02_I1.X8C\n",
      "D02_I1.X8C\n",
      "  32\tDM  B1 - 1\n",
      "1\n",
      "  22\tAR  NS - 'B1G1X1'\n",
      "'B1G1X1'\n",
      "  21\tCTS CR - D0300A\n",
      "D0300A\n",
      "1151\tT1  NS - '@F@85@ EN QFC Coil P. Shear Tab. Air Float'\n",
      "'@F@85@ EN QFC Coil P. Shear Tab. Air Float'\n",
      "1199\tX1  N2 < 0%\n",
      "0%\n",
      "1200\tX2  N2 < SEND07.QS\n",
      "SEND07.QS\n",
      "1201\tI   B1 < EN_MES.Q,'EN_MES'&\n",
      "EN_MES.Q\n",
      " 566\tLZU NF < #10000[ms],'RunTime '  \"Run time monitoring\"\n",
      "#10000[ms]\n",
      "1207\tX2  N2 < 18.298%                \"18,3 representa 3000 kg\"\n",
      "18.298%\n",
      "1283\tX2  NF < #0\n",
      "#0\n",
      "1304\tX2  NF < #26,'GRAUS'\n",
      "#26\n",
      " 905\tX2  NF < #100.0000000E3\n",
      "#100.0000000E3\n",
      "1074\tY   NF > @TYP=TF,$PTTI_A,'PTTI_AUT'&\n",
      "$PTTI_A\n",
      "1073\tX   NF < @TYP=TF,10[S]\n",
      "10[S]\n",
      "2983\tX2  NF < #530.0000000E-3,'m'\n",
      "#530.0000000E-3\n",
      " 439\tFBU NF < #500[ms],'Feedback'    \"Feedback monitoring\"\n",
      "#500[ms]\n",
      " 494\tI   B1 < STG641.Q\n",
      "STG641.Q\n",
      " 495\tY   N2 > @TYP=V2\n",
      "None\n",
      "  17\tX1  NF < $XIHW05,SCAL=1[m]\n",
      "$XIHW05\n",
      " 374\tT   TF <  3           [s]\n",
      "3           [s]\n",
      " 169\tT   TF <            2[s ]\n",
      "2[s ]\n",
      "2946\tOR  V2 < 0B00000000 00000000\n",
      "0B00000000 00000000\n",
      " 108\tX05 NF < #2500.0[V/(m/s)],'ky'  \"Scaling factor for control output\"&\n",
      "#2500.0[V/(m/s)]\n",
      "2756\tCRT TR = !EXM504\n",
      "!EXM504\n",
      " 337\tQ1  B1 >\n",
      "None\n",
      "1407\tT   TF < #2.5 [s]\n",
      "#2.5 [s]\n",
      "  87\tQ3  B1 > $E_STOP PN,'E_STOP'&\n",
      "$E_STOP PN\n"
     ]
    }
   ],
   "source": [
    "#n = re.search(\"^(((?!old).)*).((cfp)|(ofp))$\", 'pray1___20131208.cfp')\n",
    "test_txt = []\n",
    "test_txt.append(\" 325\tI1  B1 < VIHW09.Q15&\")\n",
    "test_txt.append('  81\tIS  V2 < $VISW17')\n",
    "test_txt.append(\" 163\tQ1  B1 > ,'Man__CPS'            \\\"MAINTENANCE COIL PREP STATION\\\"\")\n",
    "test_txt.append(' 115\tI1  B1 < VIHW17.Q2&')\n",
    "test_txt.append(' 519\tX1  N2 < @TYP=V2,0HFFFF')\n",
    "test_txt.append(' 520\tX2  N2 < @TYP=V2,LB2.QS&')\n",
    "test_txt.append(' 527\tQS  V2 > $VGAU02                \"Diagnose 2nd direction\"')\n",
    "test_txt.append(' 528\tQ   B1 > ')\n",
    "test_txt.append(\"  31\tAD  NK = D02_I1.X8C\")\n",
    "test_txt.append(\"  32\tDM  B1 - 1\")\n",
    "test_txt.append(\"  22\tAR  NS - 'B1G1X1'\")\n",
    "test_txt.append(\"  21\tCTS CR - D0300A\")\n",
    "test_txt.append(\"1151\tT1  NS - '@F@85@ EN QFC Coil P. Shear Tab. Air Float'\")\n",
    "test_txt.append(\"1199\tX1  N2 < 0%\")\n",
    "test_txt.append(\"1200\tX2  N2 < SEND07.QS\")\n",
    "test_txt.append(\"1201\tI   B1 < EN_MES.Q,'EN_MES'&\")\n",
    "test_txt.append(\" 566\tLZU NF < #10000[ms],'RunTime '  \\\"Run time monitoring\\\"\")\n",
    "test_txt.append(\"1207\tX2  N2 < 18.298%                \\\"18,3 representa 3000 kg\\\"\")\n",
    "test_txt.append(\"1283\tX2  NF < #0\")\n",
    "test_txt.append(\"1304\tX2  NF < #26,'GRAUS'\")\n",
    "test_txt.append(\" 905\tX2  NF < #100.0000000E3\")\n",
    "test_txt.append(\"1074\tY   NF > @TYP=TF,$PTTI_A,'PTTI_AUT'&\")\n",
    "test_txt.append(\"1073\tX   NF < @TYP=TF,10[S]\")\n",
    "test_txt.append(\"2983\tX2  NF < #530.0000000E-3,'m'\")\n",
    "test_txt.append(\" 439\tFBU NF < #500[ms],'Feedback'    \\\"Feedback monitoring\\\"\")\n",
    "test_txt.append(\" 494\tI   B1 < STG641.Q\")\n",
    "test_txt.append(\" 495\tY   N2 > @TYP=V2\")\n",
    "test_txt.append(\"  17\tX1  NF < $XIHW05,SCAL=1[m]\")\n",
    "test_txt.append(\" 374\tT   TF <  3           [s]\")\n",
    "test_txt.append(\" 169\tT   TF <            2[s ]\")\n",
    "test_txt.append(\"2946\tOR  V2 < 0B00000000 00000000\")\n",
    "test_txt.append(\" 108\tX05 NF < #2500.0[V/(m/s)],'ky'  \\\"Scaling factor for control output\\\"&\")\n",
    "test_txt.append(\"2756\tCRT TR = !EXM504\")\n",
    "test_txt.append(\" 337\tQ1  B1 >\")\n",
    "test_txt.append(\"1407\tT   TF < #2.5 [s]\")\n",
    "test_txt.append(\"  87\tQ3  B1 > $E_STOP PN,'E_STOP'&\")\n",
    "\n",
    "test_txt2 = \" 439\tFBU NF < #500[ms],'Feedback'    \\\"Feedback monitoring\\\"\"\n",
    "\n",
    "\n",
    "#m = re.compile(r\"^\\s*\\d+\\s+(\\w+)\\s+(\\w+)\\s+([<>])\\s+(@TYP=(..),)?([^@\\\"',&]+)([,\\\"'&]|$)\", )\n",
    "m = re.compile(r\"\"\"\n",
    "        ^\\s*\\d+\\s+ #string number\n",
    "        (\\w+)\\s+   #signal name \n",
    "        (\\w+)\\s+   #signal type \n",
    "        ([<>=-])\\s*  #signal delimiter \n",
    "        (@TYP=(..),?)? #singal type\n",
    "        (   #value\n",
    "        ([a-zA-Z0-9_.]+)|  #can be connection to other block\n",
    "        ([$%!\\[\\]/()a-zA-Z0-9_.#-]+)|  #can be value\n",
    "        ([$a-zA-Z0-9_]+\\s*[$a-zA-Z0-9_]*)|  #can be virtual connection\n",
    "        ([#0-9.]+\\s*\\[.*\\])|  #can be time with spaces\n",
    "        ([0-9B]+\\s+[0-9]+)|  #can be hex in bit representation\n",
    "        ('.*') #can be text\n",
    "        )? #end of value\n",
    "        (,)? #divider\n",
    "        ('.*')? #link comment\n",
    "        (,.*)? #some comment\n",
    "        (\\s+\".*\")? #signal comment\n",
    "        (&)? #check next string\n",
    "        ($) #end of string\n",
    "        \"\"\", re.X)\n",
    "k = re.compile(r\"^\\s*\\d+\\s+(\\w+)\\s+(\\w+)\\s+([<>=-])\")\n",
    "\n",
    "for a in test_txt:\n",
    "    n = m.search(a)\n",
    "    print(a)\n",
    "    #print(n.group(1),n.group(2),n.group(3),n.group(5),n.group(6),n.group(13))\n",
    "    print(n.group(6))\n",
    "    #print(n)\n",
    "    \n",
    "#n = m.search(test_txt2)\n",
    "#print(\"OUT:\",n.group(1),n.group(2),n.group(3),n.group(6),n.group(13))\n",
    "\n",
    "#for a in test_txt:\n",
    "#    n = k.search(a)\n",
    "#    print(n)\n",
    "\n",
    "#for a in test_txt:\n",
    "#    n = k.search(a)\n",
    "#    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object; span=(0, 37), match=' 830\\t   $DIADE  T4 < PN     PN-D01_P1'>\n",
      "$DIADE < PN-D01_P1\n"
     ]
    }
   ],
   "source": [
    "#test_txt=\"   &\tV4.2.6 FP-COP CHK 22.02.;9 07:54  (MP-TX04.PN-D05_P2 13.09.;6 05:02)\"\n",
    "#test_txt = \"   1 PN-D01_P1\"\n",
    "#test_txt = \"1832\t*\"\n",
    "#test_txt = \"\"\n",
    "#test_txt = \"  89 Connector list of the function packets\"\n",
    "#test_txt = \"1816\tFP-@SEND1,COM\"\n",
    "#test_txt = \"1679\t   $VINS02 T4 < PN     PN-D01_P1\"\n",
    "test_txt = \" 830\t   $DIADE  T4 < PN     PN-D01_P1\"\n",
    "\n",
    "#cp = re.compile(r'^\\s+\\d+\\s+([a-zA-Z0-9_-]+)$')\n",
    "#cp = re.compile(r'^\\s+\\d+\\s+Connector list of the function packets')\n",
    "#cp = re.compile(r'^\\s*\\d+\\s+\\*')\n",
    "#cp = re.compile(r'^\\s*\\d+\\s+FP-([a-zA-Z0-9_\\-@]+)')\n",
    "cp = re.compile(r'^\\s*\\d+\\s+(\\$[a-zA-Z0-9_\\-@]+)\\s+([\\w]+)\\s((<)|(>))\\s([\\w]+)\\s+([a-zA-Z0-9_-]+)$')\n",
    "cp_s = cp.search(test_txt)\n",
    "print(cp_s)\n",
    "print(cp_s.group(1),cp_s.group(3),cp_s.group(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEND01.I9\n",
      "KA1014.I2,KA1015.I2\n"
     ]
    }
   ],
   "source": [
    "test_txt = []\n",
    "test_txt.append(\"   &\t\t(SEND01.I9)\")\n",
    "test_txt.append('   &\t\t(KA1014.I2,KA1015.I2)')\n",
    "k = re.compile(r\"^\\s*&+\\s+\\((.*)\\)\\s*$\")\n",
    "for a in test_txt:\n",
    "    n = k.search(a)\n",
    "    print(n.group(1))\n",
    "    #print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################row data generating library#################\n",
    "NAME,TYPE_BASE,INOUT,TYPE_CONV,VALUE,CPU,CPU_SOURCE,CPU_LINK,CHART,BLOCK, LINKS  = 0,1,2,3,4,5,6,7,8,9,10\n",
    "\n",
    "#open chart for reading\n",
    "def sd_open_chart(chart_addr):\n",
    "    try:\n",
    "        with open(chart_addr) as f:\n",
    "            lines = [line.rstrip('\\n') for line in f]\n",
    "    except EnvironmentError: # parent of IOError, OSError *and* WindowsError where available\n",
    "        #print('ERROR File not exists!')\n",
    "        return -1\n",
    "    return lines\n",
    "\n",
    "#generate chart mapping: line {block name:[block line begin, block line end]}\n",
    "def sd_get_chart_map(inp_line):\n",
    "    b = re.compile(r\"^\\s*\\d+ ?([a-zA-Z0-9_]+) +: [a-zA-Z0-9_.@]+\\s*,\\s*POS=\")\n",
    "    el = re.compile(r'^ *\\d+\\s+[+]')\n",
    "    #cp = re.compile(r'\\(([a-zA-Z0-9_-]+).([a-zA-Z0-9_-]+)\\s+\\S+\\s+\\S+\\)') #not used, because not all charts consist\n",
    "    block_list = []\n",
    "    mark_bloc = False\n",
    "    #mark_cpu = False\n",
    "    out_dict = dict()\n",
    "    line_counter = 0\n",
    "    for k in inp_line:\n",
    "        #Find rack name and cpu name, e.g. MP-TX04 PN-D05_P2\n",
    "        #if not mark_cpu:\n",
    "        #    cp_s = cp.search(k)\n",
    "        #    if cp_s :\n",
    "        #        rack,cpu = cp_s.group(1),cp_s.group(2)\n",
    "        #        mark_cpu = True\n",
    "        b_s = b.search(k)\n",
    "        if b_s :\n",
    "            mark_bloc = True\n",
    "            curr_block_name = b_s.group(1)\n",
    "            block_list.append(curr_block_name)\n",
    "            mark_bloc_line_beg = line_counter\n",
    "        elif el.search(k):\n",
    "            if mark_bloc:\n",
    "                mark_bloc = False\n",
    "                out_dict[curr_block_name] = [mark_bloc_line_beg,line_counter]\n",
    "        line_counter = line_counter+1        \n",
    "    #print(len(block_list))\n",
    "    if(out_dict):\n",
    "        return out_dict\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "#check if line is signal or link\n",
    "def sd_check_line_signal(line):\n",
    "    sf = re.compile(r\"^\\s*\\d+\\s+(\\w+)\\s+(\\w+)\\s+([<>=-])\")\n",
    "    sa = re.compile(r\"^\\s*&+\\s+(\\(.*\\))\\s*$\")\n",
    "    if sf.search(line):\n",
    "        out = 1 #signal\n",
    "    elif sa.search(line):\n",
    "        out = 2 #link\n",
    "    else:\n",
    "        out = 0 #nothing\n",
    "    return out\n",
    "\n",
    "#extract data from signal line\n",
    "def sd_get_line_data(line): \n",
    "    m = re.compile(r\"\"\"\n",
    "        ^\\s*\\d+\\s+ #string number\n",
    "        (\\w+)\\s+   #signal name \n",
    "        (\\w+)\\s+   #signal type \n",
    "        ([<>=-])\\s*  #signal delimiter \n",
    "        (@TYP=(..),?)? #singal type\n",
    "        (   #value\n",
    "        ([a-zA-Z0-9_.]+)|  #can be connection to other block\n",
    "        ([$%!\\[\\]/()a-zA-Z0-9_.#-]+)|  #can be value\n",
    "        ([$a-zA-Z0-9_]+\\s*[$a-zA-Z0-9_]*)|  #can be virtual connection\n",
    "        ([#0-9.]+\\s*\\[.*\\])|  #can be time with spaces\n",
    "        ([0-9B]+\\s+[0-9]+)|  #can be hex in bit representation\n",
    "        ('.*') #can be text\n",
    "        )? #end of value\n",
    "        (,)? #divider\n",
    "        ('.*')? #link comment\n",
    "        (,.*)? #some comment\n",
    "        (\\s+\".*\")? #signal comment\n",
    "        (&)? #check next string\n",
    "        ($) #end of string\n",
    "        \"\"\", re.X)\n",
    "    #print(line)\n",
    "    n = m.search(line)\n",
    "    try: \n",
    "        out = list([n.group(1),n.group(2),n.group(3),n.group(5),n.group(6)])\n",
    "    except:\n",
    "        print(line)\n",
    "        raise\n",
    "        \n",
    "                 #name      type       dir        type_conv  value      \n",
    "    return list([n.group(1),n.group(2),n.group(3),n.group(5),n.group(6)])\n",
    "\n",
    "#exstract link from like\n",
    "def sd_get_line_link(line): \n",
    "    m = re.compile(r\"^\\s*&+\\s+\\((.*)\\)\\s*$\")\n",
    "    n = m.search(line)     \n",
    "    return n.group(1)  \n",
    "\n",
    "#get block data: signals, values, links, data types...\n",
    "def sd_get_block_data(lines,chart,block,data_link_map_df):\n",
    "\n",
    "    mark_signal_row_name = None\n",
    "    mark_signal_row_data = list([[],[]]) #[[signal data],[links]]\n",
    "    mark_block_row_data = []\n",
    "    count = 0;\n",
    "    for l in lines:\n",
    "        line_check_result = sd_check_line_signal(l)\n",
    "        if line_check_result:\n",
    "            if line_check_result==1:  \n",
    "                #if found a signal line\n",
    "                count = count+1\n",
    "                #add previous signal to preparation table\n",
    "                if mark_signal_row_name:\n",
    "                    #print(\"Old name:\",mark_signal_row_name)\n",
    "                    mark_block_row_data.append(mark_signal_row_data)\n",
    "                    mark_signal_row_data = list([[],[]]) #reset buffer table\n",
    "                #NAME,TYPE_BASE,INOUT,TYPE_CONV,VALUE\n",
    "                mark_signal_row_data[0] = sd_get_line_data(l)\n",
    "                #get CPU\n",
    "                cpu = sd_get_chart_cpu(data_link_map_df,chart)\n",
    "                mark_signal_row_data[0].append(cpu)\n",
    "                #If value is $LINK here is a logic:\n",
    "                #Copy value $LINK to link column\n",
    "                if re.search(r'^\\$',str(mark_signal_row_data[0][VALUE])) and mark_signal_row_data[0][INOUT]==\"<\":\n",
    "                    \n",
    "                    link = mark_signal_row_data[0][VALUE]\n",
    "                    print(\"move val to link\",link)\n",
    "                    mark_signal_row_data[1].extend([link])\n",
    "                    #get CPU_SOURCE\n",
    "                    cpu_source = sd_get_block_link_source_cpu(data_link_map_df,mark_signal_row_data[0][VALUE],chart)\n",
    "                    mark_signal_row_data[0].append(cpu_source)\n",
    "                    #get CPU_LINK   (means CPU_SOURCE_LINK)\n",
    "                    mark_signal_row_data[0].append(cpu_source+\"_\"+link)\n",
    "                else:\n",
    "                    #get CPU_SOURCE\n",
    "                    mark_signal_row_data[0].append(cpu)\n",
    "                    #get CPU_LINK   (means CPU_SOURCE_LINK)\n",
    "                    mark_signal_row_data[0].append(None)\n",
    "                    \n",
    "                mark_signal_row_name = mark_signal_row_data[0][NAME]\n",
    "                #get CHART,BLOCK\n",
    "                mark_signal_row_data[0].append(chart)\n",
    "                mark_signal_row_data[0].append(block)\n",
    "            elif line_check_result==2:\n",
    "                #if found a link line: (SOMETHING,SOMETHING2)\n",
    "                mark_signal_row_data[1].extend(sd_get_line_link(l).split(','))\n",
    "            #print(mark_signal_row_data)            \n",
    "        else:\n",
    "            pass #skip string\n",
    "    #Add last signal to preparation storage\n",
    "    mark_block_row_data.append(mark_signal_row_data)\n",
    "    return mark_block_row_data\n",
    "\n",
    "#convert list to pandas data frame\n",
    "def sd_conv_block_data_to_df(block_data):\n",
    "    #list element of row signal data:[[NAME,TYPE_BASE,INOUT,TYPE_CONV,VALUE],[links]]\n",
    "    block_df = pd.DataFrame([[j for j in k[0]]+[k[1]] for k in block_data])\n",
    "    return block_df\n",
    "#convert list to better representation\n",
    "def sd_conv_block_data_to_list(block_data):\n",
    "    #list element of row signal data:[[NAME,TYPE_BASE,INOUT,TYPE_CONV,VALUE,CPU,CPU_SOURCE,CPU_LINK,CHART,BLOCK],[links]]\n",
    "    block_data_list = [[j for j in k[0]]+[k[1]] for k in block_data]\n",
    "    return block_data_list\n",
    "\n",
    "\n",
    "#create df row with link source structure: chart_block_signal,cpu_link\n",
    "def sd_get_source_link(block_data_list):\n",
    "    #block_data_list: (NAME,TYPE_BASE,INOUT,TYPE_CONV,VALUE,CPU,CPU_SOURCE,CPU_LINK,CHART,BLOCK ),LINKS\n",
    "    m = re.compile(r\"^\\$\\w+\")\n",
    "    out_df = []\n",
    "    for j in block_data_list:\n",
    "        if j[INOUT]==\">\":\n",
    "            if(j[VALUE]):\n",
    "                n = m.search(j[VALUE]) \n",
    "                #print(k)\n",
    "                if n:\n",
    "                    #chart/block.signal,cpu_link\n",
    "                    chart_block_signal = j[CHART].upper()+'/'+j[BLOCK].upper()+'.'+j[NAME].upper()\n",
    "                    cpu_link = j[CPU]+'_'+j[VALUE]\n",
    "                    #print(chart_block_signal,\"=>\",cpu_link)\n",
    "                    out_df.append([chart_block_signal,cpu_link])\n",
    "            #look for source link in link array\n",
    "            for k in j[LINKS]:\n",
    "                print(k)\n",
    "                if(k):\n",
    "                    n = m.search(k) \n",
    "                    #print(k)\n",
    "                    if n:\n",
    "                        #chart/block.signal,cpu_link\n",
    "                        chart_block_signal = j[CHART].upper()+'/'+j[BLOCK].upper()+'.'+j[NAME].upper()\n",
    "                        cpu_link = j[CPU]+'_'+k\n",
    "                        #print(chart_block_signal,\"=>\",cpu_link)\n",
    "                        out_df.append([chart_block_signal,cpu_link])\n",
    "    return out_df\n",
    "\n",
    "#generate data of all charts and generate data of link sources\n",
    "def sd_build_data_s1(sd_chart_list,data_link_map_df):\n",
    "    \n",
    "    data_list = []\n",
    "    data_link_source_list = []\n",
    "    for i in sd_chart_list:\n",
    "        for (k,v) in sd_chart_list[i].items(): \n",
    "            chart = k.upper()\n",
    "            chart_lines = sd_open_chart(v)\n",
    "            chart_mapping = sd_get_chart_map(chart_lines)\n",
    "            print(\"Parsing '%s' chart with %s functions\"%(chart,len(chart_mapping)))\n",
    "            for block_map in chart_mapping:\n",
    "                #generating array 'signal','type_base','inout','type_conv','value','link','chart','block','cpu'\n",
    "                block_lines = chart_lines[chart_mapping[block_map][0]:chart_mapping[block_map][1]]\n",
    "                #get block data: NAME,TYPE_BASE,INOUT,TYPE_CONV,VALUE,CPU,CPU_SOURCE,CPU_LINK,CHART,BLOCK\n",
    "                block_data = sd_get_block_data(block_lines,chart,block_map,data_link_map_df)\n",
    "                #print(\"before \",block_data)\n",
    "                #print(\"-- \")\n",
    "                block_data_list = sd_conv_block_data_to_list(block_data)\n",
    "                print(\"after \",block_data_list)\n",
    "                print(\"-- \")\n",
    "                #Add block data to accumulation list\n",
    "                data_list.extend(block_data_list)\n",
    "                #create link source array\n",
    "                block_link_source_list = sd_get_source_link(block_data_list)\n",
    "                raise\n",
    "                if len(block_link_source_list)!=0:\n",
    "                    #print(block_link_source_list)\n",
    "                    data_link_source_list.extend(block_link_source_list) \n",
    "    #Convert to DataFrame for easy work\n",
    "    data_link_source_df = pd.DataFrame(data_link_source_list, columns=['chart_block_signal','cpu_link'])\n",
    "    data_df = pd.DataFrame(data_list, columns=['signal','type_base','inout','type_conv','value','cpu',\\\n",
    "                                                         'cpu_source','cpu_link','chart','block','link'])\n",
    "    return data_df,data_link_source_df\n",
    "\n",
    "#parsing mapping file\n",
    "#generate cpu,link db by cpu mapping file\n",
    "def sd_build_cpu_map(sd_chart_list):\n",
    "    data_link_map_list = []\n",
    "    cp = re.compile(r'^\\s+\\d+\\s+([a-zA-Z0-9_-]+)$') #find CPU name in file\n",
    "    bg = re.compile(r'^\\s+\\d+\\s+Connector list of the function packets') # find beginning of link information\n",
    "    en = re.compile(r'^\\s*\\d+\\s+\\*')\n",
    "    ch = re.compile(r'^\\s*\\d+\\s+FP-([a-zA-Z0-9_\\-@]+)')\n",
    "    lk = re.compile(r'^\\s*\\d+\\s+(\\$[a-zA-Z0-9_\\-@]+)\\s+([\\w]+)\\s((<)|(>))\\s([\\w]+)\\s+([a-zA-Z0-9_-]+)$')\n",
    "    \n",
    "    for i in sd_chart_list:\n",
    "        for (k,v) in sd_chart_list[i].items():\n",
    "            chart_lines = sd_open_chart(v)\n",
    "            print(\"Parsing '%s' chart \"%(k))\n",
    "            cpu_mark = False\n",
    "            beg_mark = False\n",
    "            end_mark = False\n",
    "            for l in chart_lines:\n",
    "                ##Find CPU name\n",
    "                if not cpu_mark:\n",
    "                    cp_s = cp.search(l)\n",
    "                    if cp_s :\n",
    "                        cpu = cp_s.group(1)\n",
    "                        cpu_mark = True\n",
    "                        print(cpu)   \n",
    "                else:\n",
    "                    if not beg_mark:\n",
    "                        if bg.search(l):\n",
    "                            beg_mark = True\n",
    "                    else:\n",
    "                        #check end\n",
    "                        if en.search(l):\n",
    "                            end_mark = True\n",
    "                            break\n",
    "                        else:\n",
    "                            #main block:\n",
    "                            ch_s = ch.search(l)\n",
    "                            if ch.search(l): #if chart beginning 1739\tFP-MONIW1\n",
    "                                chart = ch_s.group(1)\n",
    "                            else:\n",
    "                                lk_s = lk.search(l)\n",
    "                                if lk_s: #if chart link definition 1744\t   $DMALB1 T5 < PN     PN-D01_P1\n",
    "                                    #'cpu','chart','out','link','cpu_source'\n",
    "                                    data_link_map_list.append([cpu, chart.upper(),lk_s.group(3),lk_s.group(1),lk_s.group(7)])\n",
    "    data_link_map_df = pd.DataFrame(data_link_map_list, columns=['cpu','chart','out','link','cpu_source'])\n",
    "    return data_link_map_df\n",
    "\n",
    "def sd_get_chart_cpu(data_link_map_df,chart):\n",
    "    return data_link_map_df[data_link_map_df['chart']==chart].iloc[0]['cpu']\n",
    "\n",
    "def sd_get_block_link_source_cpu(data_link_map_df,link,chart):\n",
    "    return data_link_map_df[(data_link_map_df['chart']==chart)&\\\n",
    "                            (data_link_map_df['link']==link)&\\\n",
    "                            (data_link_map_df['out']==\"<\")].iloc[0]['cpu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing '1tx04' chart \n",
      "PN-D01_P1\n",
      "Parsing '2tx04' chart \n",
      "PN-D05_P2\n",
      "Parsing '3tx04' chart \n",
      "PN-D08_P3\n",
      "Parsing 'ENBRI1' chart with 70 functions\n",
      "move val to link $VPAR01\n",
      "after  [['IS', 'V2', '<', None, '$VPAR01', 'PN-D01_P1', 'PN-D01_P1', 'PN-D01_P1_$VPAR01', 'ENBRI1', 'VPAR01', ['$VPAR01']], ['Q1', 'B1', '>', None, None, 'PN-D01_P1', 'PN-D01_P1', None, 'ENBRI1', 'VPAR01', []], ['Q2', 'B1', '>', None, None, 'PN-D01_P1', 'PN-D01_P1', None, 'ENBRI1', 'VPAR01', []], ['Q3', 'B1', '>', None, None, 'PN-D01_P1', 'PN-D01_P1', None, 'ENBRI1', 'VPAR01', []], ['Q4', 'B1', '>', None, None, 'PN-D01_P1', 'PN-D01_P1', None, 'ENBRI1', 'VPAR01', []], ['Q5', 'B1', '>', None, None, 'PN-D01_P1', 'PN-D01_P1', None, 'ENBRI1', 'VPAR01', []], ['Q6', 'B1', '>', None, None, 'PN-D01_P1', 'PN-D01_P1', None, 'ENBRI1', 'VPAR01', []], ['Q7', 'B1', '>', None, None, 'PN-D01_P1', 'PN-D01_P1', None, 'ENBRI1', 'VPAR01', []], ['Q8', 'B1', '>', None, None, 'PN-D01_P1', 'PN-D01_P1', None, 'ENBRI1', 'VPAR01', []], ['Q9', 'B1', '>', None, None, 'PN-D01_P1', 'PN-D01_P1', None, 'ENBRI1', 'VPAR01', []], ['Q10', 'B1', '>', None, None, 'PN-D01_P1', 'PN-D01_P1', None, 'ENBRI1', 'VPAR01', []], ['Q11', 'B1', '>', None, None, 'PN-D01_P1', 'PN-D01_P1', None, 'ENBRI1', 'VPAR01', []], ['Q12', 'B1', '>', None, None, 'PN-D01_P1', 'PN-D01_P1', None, 'ENBRI1', 'VPAR01', []], ['Q13', 'B1', '>', None, None, 'PN-D01_P1', 'PN-D01_P1', None, 'ENBRI1', 'VPAR01', []], ['Q14', 'B1', '>', None, None, 'PN-D01_P1', 'PN-D01_P1', None, 'ENBRI1', 'VPAR01', []], ['Q15', 'B1', '>', None, None, 'PN-D01_P1', 'PN-D01_P1', None, 'ENBRI1', 'VPAR01', ['AND_01.I2']], ['Q16', 'B1', '>', None, None, 'PN-D01_P1', 'PN-D01_P1', None, 'ENBRI1', 'VPAR01', ['STGO2.I4', 'STGO4.I1', 'XTGO2.I4']]]\n",
      "-- \n",
      "AND_01.I2\n",
      "STGO2.I4\n",
      "STGO4.I1\n",
      "XTGO2.I4\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-341-8f5cdd36ad6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata_lm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msd_build_cpu_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msd_cpu_charts_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdata_s1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_ls1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msd_build_data_s1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msd_chart_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_lm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdata_s1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"block\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_s1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"block\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-340-ba2cbb48a390>\u001b[0m in \u001b[0;36msd_build_data_s1\u001b[0;34m(sd_chart_list, data_link_map_df)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0;31m#create link source array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0mblock_link_source_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msd_get_source_link\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_data_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_link_source_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                     \u001b[0;31m#print(block_link_source_list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "#execution cell\n",
    "#creating row data DataFrame \"data_s1\" from chart list\n",
    "        \n",
    "data_lm = sd_build_cpu_map(sd_cpu_charts_list)\n",
    "data_s1,data_ls1 = sd_build_data_s1(sd_chart_list,data_lm)\n",
    "\n",
    "data_s1[\"block\"] = data_s1[\"block\"].astype(str)\n",
    "\n",
    "#save intermidiate result\n",
    "#data_s1.to_csv(os.path.join(PATH_TO_DATA,FILE_NAME_TEMP1))\n",
    "\n",
    "data_s1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chart_block_signal</th>\n",
       "      <th>cpu_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [chart_block_signal, cpu_link]\n",
       "Index: []"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ls1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#restore intermediate result\n",
    "data_s1 = pd.read_csv(os.path.join(PATH_TO_DATA,FILE_NAME_TEMP1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rectify function: move Links \"AAA.AA\" of inputs to row \"link\"\n",
    "def sd_rect_data_s1(data_df):\n",
    "    def filter_func_output(x):\n",
    "        if(re.search(r'(\\S+[.]\\D+)',str(x[4]))):\n",
    "            x[5]=[x[4]]\n",
    "        return x\n",
    "    return data_df.apply(filter_func_output, axis = 1)\n",
    "\n",
    "#rectify function: add block \"chartblock\"\n",
    "def sd_rect_data_s2(data_df):\n",
    "    data_df['chartblock'] = data_df[\"chart\"].str.upper()+\"/\"+data_df[\"block\"].str.upper()\n",
    "    return data_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_s1 = sd_rect_data_s1(data_s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_s2 = sd_rect_data_s2(data_s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cpu</th>\n",
       "      <th>chart</th>\n",
       "      <th>out</th>\n",
       "      <th>link</th>\n",
       "      <th>cpu_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>PN-D01_P1</td>\n",
       "      <td>ENGN11</td>\n",
       "      <td>&gt;</td>\n",
       "      <td>$VGN103</td>\n",
       "      <td>PN-D01_P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>PN-D01_P1</td>\n",
       "      <td>ENMAN1</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>$VGN103</td>\n",
       "      <td>PN-D01_P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>PN-D01_P1</td>\n",
       "      <td>ENBRI1</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>$VGN103</td>\n",
       "      <td>PN-D01_P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>PN-D01_P1</td>\n",
       "      <td>ENBEA1</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>$VGN103</td>\n",
       "      <td>PN-D01_P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>PN-D01_P1</td>\n",
       "      <td>ENSR_1</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>$VGN103</td>\n",
       "      <td>PN-D01_P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>PN-D01_P1</td>\n",
       "      <td>ENCC_1</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>$VGN103</td>\n",
       "      <td>PN-D01_P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>PN-D01_P1</td>\n",
       "      <td>ENOHW1</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>$VGN103</td>\n",
       "      <td>PN-D01_P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>PN-D01_P1</td>\n",
       "      <td>ENOSW1</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>$VGN103</td>\n",
       "      <td>PN-D01_P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>PN-D01_P1</td>\n",
       "      <td>MESY_1</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>$VGN103</td>\n",
       "      <td>PN-D01_P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>PN-D05_P2</td>\n",
       "      <td>EXGN12</td>\n",
       "      <td>&gt;</td>\n",
       "      <td>$VGN103</td>\n",
       "      <td>PN-D05_P2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>PN-D05_P2</td>\n",
       "      <td>EXTB_2</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>$VGN103</td>\n",
       "      <td>PN-D05_P2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2705</th>\n",
       "      <td>PN-D05_P2</td>\n",
       "      <td>EXOHW2</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>$VGN103</td>\n",
       "      <td>PN-D05_P2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2979</th>\n",
       "      <td>PN-D05_P2</td>\n",
       "      <td>MESY_2</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>$VGN103</td>\n",
       "      <td>PN-D05_P2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            cpu   chart out     link cpu_source\n",
       "309   PN-D01_P1  ENGN11   >  $VGN103  PN-D01_P1\n",
       "474   PN-D01_P1  ENMAN1   <  $VGN103  PN-D01_P1\n",
       "583   PN-D01_P1  ENBRI1   <  $VGN103  PN-D01_P1\n",
       "618   PN-D01_P1  ENBEA1   <  $VGN103  PN-D01_P1\n",
       "649   PN-D01_P1  ENSR_1   <  $VGN103  PN-D01_P1\n",
       "683   PN-D01_P1  ENCC_1   <  $VGN103  PN-D01_P1\n",
       "1248  PN-D01_P1  ENOHW1   <  $VGN103  PN-D01_P1\n",
       "1308  PN-D01_P1  ENOSW1   <  $VGN103  PN-D01_P1\n",
       "1547  PN-D01_P1  MESY_1   <  $VGN103  PN-D01_P1\n",
       "1897  PN-D05_P2  EXGN12   >  $VGN103  PN-D05_P2\n",
       "2215  PN-D05_P2  EXTB_2   <  $VGN103  PN-D05_P2\n",
       "2705  PN-D05_P2  EXOHW2   <  $VGN103  PN-D05_P2\n",
       "2979  PN-D05_P2  MESY_2   <  $VGN103  PN-D05_P2"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_df = data_s1.copy()\n",
    "#test_df[test_df['link'].apply(lambda x: bool(re.search(r\"\\$\\w+\\s+\\w+\",str(x)))==True)]\n",
    "test_df = data_lm.copy()\n",
    "#test_df[test_df['link'].apply(lambda x: bool(any(\"$\" in s for s in x) and len(x)>1)==True)]\n",
    "test_df[(test_df['link']=='$VGN103')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#report generator of comparison of block in all SD and TDC charts\n",
    "def report_find_miss_blocks (data_sd,data_tdc, to_file = True, timestamp = datetime.datetime.now()):\n",
    "    README_HEADER = COMPARATOR_README +\"\\\n",
    "\\r\\nReport: find missing blocks in TDC program\\\n",
    "\\r\\nDate ant time of report generation: %s \\\n",
    "\\r\\n===================================================================================\\\n",
    "\\r\\n\"%(str(timestamp))\n",
    "    \n",
    "    def generate_report(f):\n",
    "        print(README_HEADER,file = f) \n",
    "        sd_uniq_blocks = data_sd['chartblock'].unique()\n",
    "        tdc_uniq_blocks = data_tdc['chartblock'].unique()\n",
    "        for i in sd_uniq_blocks:\n",
    "            if not i in tdc_uniq_blocks:\n",
    "                print(\"Missing block in TDC: \",i,\"\\r\\n\",file = f) \n",
    "        \n",
    "        \n",
    "        \n",
    "    if to_file:\n",
    "        file_suffix = \"_find_miss_blocks_sd\"\n",
    "        file_prefix = \"report_\"\n",
    "        try:\n",
    "            # Create target Directory\n",
    "            os.mkdir(os.path.join(PATH_TO_REPORTS))\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        #sys.stdout = open(os.path.join(PATH_TO_REPORTS,(file_prefix+FILE_NAME_DATA1.split(\".\")[0]+file_suffix+\".txt\")), 'w')\n",
    "        with open(os.path.join(PATH_TO_REPORTS,(file_prefix+FILE_NAME_DATA1.split(\".\")[0]+file_suffix+\".txt\")), 'w') as f: \n",
    "            generate_report(f)\n",
    "    else:\n",
    "        generate_report(sys.stdout)\n",
    "\n",
    "        #data_a1_1 = data_a1\n",
    "        #for i, j in data_a1_1.iterrows():\n",
    "        #    if(not j['out']) and not pd.isnull(j['value']):\n",
    "\n",
    "    \n",
    "    \n",
    "#test_df = data_s2.head(5000).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#############EXECUTION GENERATE REPORT report_find_miss_blocks############\n",
    "report_find_miss_blocks(data_s2,data_a1,to_file = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
