{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.6.8\n",
      "IPython 7.7.0\n",
      "\n",
      "numpy 1.17.0\n",
      "scipy 1.3.1\n",
      "pandas 0.25.0\n",
      "matplotlib 3.1.1\n",
      "sklearn 0.21.3\n",
      "\n",
      "compiler   : GCC 8.0.1 20180414 (experimental) [trunk revision 259383\n",
      "system     : Linux\n",
      "release    : 4.9.93-boot2docker\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 2\n",
      "interpreter: 64bit\n",
      "Git hash   : 85e16f8d96fcc7fa38e2ae7f1287ada7894aff7f\n"
     ]
    }
   ],
   "source": [
    "###########LIBRARY CELL###########\n",
    "# pip install watermark\n",
    "%load_ext watermark\n",
    "%watermark -v -m -p numpy,scipy,pandas,matplotlib,sklearn -g "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########LIBRARY CELL###########\n",
    "from __future__ import division, print_function\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import datetime\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================================================\r\n",
      "Advanced comparator SimadynD <=> SimadynD software version: v.33.SDSD \r\n",
      "Author: Anton Tushev \r\n",
      "Comparison StrucG folder #1: /notebooks/pinda/data/eko/190725\r\n",
      "Comparison StrucG folder #2: /notebooks/pinda/data/eko/191031\r\n",
      "List of SimadynD subfolders for parsing is ['vx21'] \r\n",
      "List of ignored charts is ['@SIMD'] \r\n",
      "===================================================================================\n"
     ]
    }
   ],
   "source": [
    "###########VERSION OF COMPARATOR FOR SD<->SD Comparison\n",
    "###########LIBRARY CELL###########\n",
    "COMPARISON_TEXT_TYPE = \"SimadynD <=> SimadynD\"\n",
    "COMPARATOR_AUTHOR = \"Anton Tushev\" \n",
    "COMPARATOR_VERSION = \"v.33.SDSD\"\n",
    "PATH_TO_DATA = '/notebooks/pinda/data'\n",
    "#PATH_TO_STRUCG_1 = '/notebooks/pinda/data/eko/test_1'\n",
    "#PATH_TO_STRUCG_2 = '/notebooks/pinda/data/eko/test_2'\n",
    "#PATH_TO_STRUCG_1 = '/notebooks/pinda/data/eko/190725_freezed'\n",
    "PATH_TO_STRUCG_1 = '/notebooks/pinda/data/eko/190725'\n",
    "PATH_TO_STRUCG_2 = '/notebooks/pinda/data/eko/191031'\n",
    "PATH_TO_REPORTS = '/notebooks/pinda/reports'\n",
    "SD_RACK_NAMES = ['vx21']\n",
    "FILE_1_NAME_TEMP1 = '@sd1_data_s1_progress_bkup.csv'\n",
    "FILE_1_NAME_TEMP2 = '@sd1_data_ls1_progress_bkup.csv'\n",
    "FILE_1_NAME_TEMP3 = '@sd1_data_lm_progress_bkup.csv'\n",
    "FILE_2_NAME_TEMP1 = '@sd2_data_s1_progress_bkup.csv'\n",
    "FILE_2_NAME_TEMP2 = '@sd2_data_ls1_progress_bkup.csv'\n",
    "FILE_2_NAME_TEMP3 = '@sd2_data_lm_progress_bkup.csv'\n",
    "IGNORE_CHART = ['@SIMD']\n",
    "###Supports ENG,DE\n",
    "SIMADYND_LANG = \"DE\" \n",
    "SKIP_CHART_NFND = False\n",
    "SKIP_BLOCK_NEXST = False\n",
    "SKIP_SIGNAL_NFND = False\n",
    "SKIP_EQUAL = True\n",
    "SKIP_TYPE_STR = False\n",
    "\n",
    "#report parameters    \n",
    "filt_type_base = ['B1','TF','N2','N4','V2','O2','V4','NF','V1','I2','TR','RR']  #,'NS'\n",
    "filt_inout = ['<','>','=','-']#,'-'\n",
    "\n",
    "COMPARATOR_README = \"===================================================================================\\\n",
    "\\r\\nAdvanced comparator %s software version: %s \\r\\nAuthor: %s \\\n",
    "\\r\\nComparison StrucG folder #1: %s\\\n",
    "\\r\\nComparison StrucG folder #2: %s\\\n",
    "\\r\\nList of SimadynD subfolders for parsing is %s \\\n",
    "\\r\\nList of ignored charts is %s \\\n",
    "\\r\\n===================================================================================\\\n",
    "\"%(COMPARISON_TEXT_TYPE, COMPARATOR_VERSION,COMPARATOR_AUTHOR,PATH_TO_STRUCG_1,PATH_TO_STRUCG_2,SD_RACK_NAMES,IGNORE_CHART)\n",
    "print(COMPARATOR_README)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###########LIBRARY CELL###########\n",
    "#Generate Simadyn chart structure\n",
    "def sd_get_chart_list(PATH_TO_STRUCG,SD_RACK_NAMES=SD_RACK_NAMES):\n",
    "    #filter chart files\n",
    "    n = re.compile(\"^(((?!old).)*).((cfp)|(ofp))$\")\n",
    "    file_list=[] \n",
    "    file_list = {rack_name:[item for item in os.listdir(os.path.join(PATH_TO_STRUCG,rack_name)) \\\n",
    "        # chart file names filter conditions\n",
    "        if os.path.isfile(os.path.join(PATH_TO_STRUCG,rack_name, item)) and (n.search(item)) and len(item)<11 \\\n",
    "        ] for rack_name in SD_RACK_NAMES}\n",
    "    file_list_filtered = dict(file_list)\n",
    "    for i in file_list:\n",
    "        for k in file_list[i]:\n",
    "            chart_name = k.split('.')[0]\n",
    "            if \"%s.cfp\"%chart_name in file_list[i]:\n",
    "                try:\n",
    "                    file_list_filtered[i].remove(\"%s.ofp\"%chart_name)\n",
    "                except ValueError:\n",
    "                    pass  # do nothing\n",
    "    out_dict = dict()\n",
    "    for i in file_list_filtered:\n",
    "        out_dict[i] = dict()\n",
    "        for k in file_list_filtered[i]:\n",
    "            out_dict[i][k.split('.')[0]]=os.path.join(PATH_TO_STRUCG,i,k)\n",
    "    if out_dict:\n",
    "        return out_dict\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "#Generate Simadyn cpu mapping structure\n",
    "def sd_get_cpu_charts_list(PATH_TO_STRUCG,SD_RACK_NAMES=SD_RACK_NAMES):\n",
    "    #filter chart files\n",
    "    n = re.compile(\"^((\\d+).*)\\.(mpn)$\")\n",
    "    file_list=[] \n",
    "    file_list=[] \n",
    "    file_list = {rack_name:[item for item in os.listdir(os.path.join(PATH_TO_STRUCG,rack_name)) \\\n",
    "        # chart file names filter conditions\n",
    "        if os.path.isfile(os.path.join(PATH_TO_STRUCG,rack_name, item)) and (n.search(item)) and len(item)<11 \\\n",
    "        ] for rack_name in SD_RACK_NAMES}\n",
    "    out_dict = dict()\n",
    "    for i in file_list:\n",
    "        out_dict[i] = dict()\n",
    "        for k in file_list[i]:\n",
    "            out_dict[i][k.split('.')[0]]=os.path.join(PATH_TO_STRUCG,i,k)\n",
    "    if out_dict:\n",
    "        return out_dict\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "###########LIBRARY CELL###########\n",
    "#########################SimadynD row data generating library#################\n",
    "NAME,TYPE_BASE,INOUT,TYPE_CONV,VALUE,CPU,CPU_SOURCE,CPU_LINK,CHART,BLOCK,LINKS  = 0,1,2,3,4,5,6,7,8,9,10\n",
    "\n",
    "#open chart for reading\n",
    "def sd_open_chart(chart_addr):\n",
    "    try:\n",
    "        with open(chart_addr) as f:\n",
    "            lines = [line.rstrip('\\n') for line in f]\n",
    "    except EnvironmentError: # parent of IOError, OSError *and* WindowsError where available\n",
    "        #print('ERROR File not exists!')\n",
    "        return -1\n",
    "    return lines\n",
    "\n",
    "#generate chart mapping: line {block name:[block line begin, block line end]}\n",
    "def sd_get_chart_map(inp_line):\n",
    "    b = re.compile(r\"^\\s*\\d+ ?([a-zA-Z0-9_]+) +: [a-zA-Z0-9_.@]+\\s*,\\s*POS=\")\n",
    "    el = re.compile(r'^ *\\d+\\s+[+]')\n",
    "    #cp = re.compile(r'\\(([a-zA-Z0-9_-]+).([a-zA-Z0-9_-]+)\\s+\\S+\\s+\\S+\\)') #not used, because not all charts consist\n",
    "    block_list = []\n",
    "    mark_bloc = False\n",
    "    #mark_cpu = False\n",
    "    out_dict = dict()\n",
    "    line_counter = 0\n",
    "    for k in inp_line:\n",
    "        #Find rack name and cpu name, e.g. MP-TX04 PN-D05_P2\n",
    "        #if not mark_cpu:\n",
    "        #    cp_s = cp.search(k)\n",
    "        #    if cp_s :\n",
    "        #        rack,cpu = cp_s.group(1),cp_s.group(2)\n",
    "        #        mark_cpu = True\n",
    "        b_s = b.search(k)\n",
    "        if b_s :\n",
    "            mark_bloc = True\n",
    "            curr_block_name = b_s.group(1)\n",
    "            block_list.append(curr_block_name)\n",
    "            mark_bloc_line_beg = line_counter\n",
    "        elif el.search(k):\n",
    "            if mark_bloc:\n",
    "                mark_bloc = False\n",
    "                out_dict[curr_block_name] = [mark_bloc_line_beg,line_counter]\n",
    "        line_counter = line_counter+1        \n",
    "    #print(len(block_list))\n",
    "    if(out_dict):\n",
    "        return out_dict\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "#check if line is signal or link\n",
    "def sd_check_line_signal(line):\n",
    "    sf = re.compile(r\"^\\s*\\d+\\s+(\\w+)\\s+(\\w+)\\s+([<>=-])\")\n",
    "    sa = re.compile(r\"^\\s*&+\\s+(\\(.*\\))\\s*$\")\n",
    "    if sf.search(line):\n",
    "        out = 1 #signal\n",
    "    elif sa.search(line):\n",
    "        out = 2 #link\n",
    "    else:\n",
    "        out = 0 #nothing\n",
    "    return out\n",
    "\n",
    "#extract data from signal line\n",
    "def sd_get_line_data(line): \n",
    "    m = re.compile(r\"\"\"\n",
    "        ^\\s*\\d+\\s+ #string number\n",
    "        (\\w+)\\s+   #signal name \n",
    "        (\\w+)\\s+   #signal type \n",
    "        ([<>=-])\\s*  #signal delimiter \n",
    "        (@TYP=(..),?)? #singal type\n",
    "        (   #value\n",
    "        ([a-zA-Z0-9_.]+)|  #can be connection to other block\n",
    "        ([$%!\\[\\]/()a-zA-Z0-9\\s_.*#\\-\\+]+)|  #can be value\n",
    "        ([$a-zA-Z0-9_]+\\s*[$a-zA-Z0-9_]*)|  #can be virtual connection\n",
    "        ([#0-9.]+\\s*\\[.*\\])|  #can be time with spaces\n",
    "        ([0-9B]+\\s+[0-9]+)|  #can be hex in bit representation\n",
    "        ('.*')| #can be text\n",
    "        (\\*[a-zA-Z0-9_.]+)  #can hardware connection: *ADRCO1\n",
    "        )? #end of value\n",
    "        ([\\s]*,)? #divider\n",
    "        (\\![a-zA-Z0-9_\\.]+)?\n",
    "        ([\\s]*,)?\n",
    "        ('.*')? #link comment\n",
    "        (,.*)? #some comment\n",
    "        (\\s*\".*\")? #signal comment\n",
    "        (&)? #check next string\n",
    "        (\\s)*\n",
    "        ($) #end of string\n",
    "        \"\"\", re.X)\n",
    "    #print(line)\n",
    "    n = m.search(line)\n",
    "    try:\n",
    "        #Check if value is XXXX but behind is telegram connection like !XXX.YY\n",
    "        if n.group(15):\n",
    "            check_val = n.group(15)\n",
    "        else:\n",
    "            check_val = n.group(6)\n",
    "        out = list([n.group(1),n.group(2),n.group(3),n.group(5),check_val])\n",
    "    except:\n",
    "        #print line for debugging\n",
    "        print(line) \n",
    "        raise\n",
    "        \n",
    "    #     #name      type       dir        type_conv  value \n",
    "    #list([n.group(1),n.group(2),n.group(3),n.group(5),n.group(6)])\n",
    "    return out\n",
    "\n",
    "#exstract link from like\n",
    "def sd_get_line_link(line): \n",
    "    m = re.compile(r\"^\\s*&+\\s+\\((.*)\\)\\s*$\")\n",
    "    n = m.search(line)     \n",
    "    return n.group(1)  \n",
    "\n",
    "#get block data: signals, values, links, data types...\n",
    "def sd_get_block_data(lines,chart,block,data_link_map_df):\n",
    "    mark_signal_row_name = None\n",
    "    mark_signal_row_data = list([[],[]]) #[[signal data],[links]]\n",
    "    mark_block_row_data = []\n",
    "    count = 0;\n",
    "    #get CPU name\n",
    "    cpu = sd_get_chart_cpu(data_link_map_df,chart)\n",
    "    #If no cpu found, it means chart is not used in SD software:\n",
    "    if cpu == -1:\n",
    "        return -1\n",
    "    for l in lines:\n",
    "        line_check_result = sd_check_line_signal(l)\n",
    "        if line_check_result:\n",
    "            if line_check_result==1:  \n",
    "                #if found a signal line\n",
    "                count = count+1\n",
    "                #add previous signal to preparation table\n",
    "                if mark_signal_row_name:\n",
    "                    #print(\"Old name:\",mark_signal_row_name)\n",
    "                    mark_block_row_data.append(mark_signal_row_data)\n",
    "                    mark_signal_row_data = list([[],[]]) #reset buffer table\n",
    "                #NAME,TYPE_BASE,INOUT,TYPE_CONV,VALUE\n",
    "                mark_signal_row_data[0] = sd_get_line_data(l)\n",
    "                mark_signal_row_data[0].append(cpu)\n",
    "                #If value is $LINK here is a logic:\n",
    "                #Copy value $LINK to link column\n",
    "                if re.search(r'^\\$',str(mark_signal_row_data[0][VALUE])) and mark_signal_row_data[0][INOUT]==\"<\":\n",
    "                    link = mark_signal_row_data[0][VALUE].split()[0] #CONVERT '$LINK PN' => '$LINK'\n",
    "                    mark_signal_row_data[1].append(link)\n",
    "                    #get CPU_SOURCE\n",
    "                    cpu_source = sd_get_block_link_source_cpu(data_link_map_df,link,chart)\n",
    "                    mark_signal_row_data[0].append(cpu_source)\n",
    "                    #get CPU_LINK   (means CPU_SOURCE_LINK)\n",
    "                    mark_signal_row_data[0].append(cpu_source+\"_\"+link)\n",
    "                else:\n",
    "                    #get CPU_SOURCE\n",
    "                    mark_signal_row_data[0].append(cpu)\n",
    "                    #get CPU_LINK   (means CPU_SOURCE_LINK)\n",
    "                    mark_signal_row_data[0].append(None)\n",
    "                    \n",
    "                mark_signal_row_name = mark_signal_row_data[0][NAME]\n",
    "                #get CHART,BLOCK\n",
    "                mark_signal_row_data[0].append(chart)\n",
    "                mark_signal_row_data[0].append(block)\n",
    "            elif line_check_result==2:\n",
    "                #if found a link line: (SOMETHING,SOMETHING2)\n",
    "                mark_signal_row_data[1].extend(sd_get_line_link(l).split(','))\n",
    "            #print(mark_signal_row_data)            \n",
    "        else:\n",
    "            pass #skip string\n",
    "    #Add last signal to preparation storage\n",
    "    mark_block_row_data.append(mark_signal_row_data)\n",
    "    return mark_block_row_data\n",
    "\n",
    "#convert list to pandas data frame\n",
    "def sd_conv_block_data_to_df(block_data):\n",
    "    #list element of row signal data:[[NAME,TYPE_BASE,INOUT,TYPE_CONV,VALUE],[links]]\n",
    "    block_df = pd.DataFrame([[j for j in k[0]]+[k[1]] for k in block_data])\n",
    "    return block_df\n",
    "#convert list to better representation\n",
    "def sd_conv_block_data_to_list(block_data):\n",
    "    #list element of row signal data:[[NAME,TYPE_BASE,INOUT,TYPE_CONV,VALUE,CPU,CPU_SOURCE,CPU_LINK,CHART,BLOCK],[links]]\n",
    "    block_data_list = [[j for j in k[0]]+[k[1]] for k in block_data]\n",
    "    return block_data_list\n",
    "\n",
    "\n",
    "#create df row with link source structure: chart_block_signal,cpu_link\n",
    "def sd_get_source_link(block_data_list):\n",
    "    #block_data_list: (NAME,TYPE_BASE,INOUT,TYPE_CONV,VALUE,CPU,CPU_SOURCE,CPU_LINK,CHART,BLOCK ),LINKS\n",
    "    m = re.compile(r\"^\\$\\w+\")\n",
    "    out_df = []\n",
    "    for j in block_data_list:\n",
    "        if j[INOUT]==\">\":\n",
    "            if(j[INOUT]):\n",
    "                \n",
    "                val = str(j[VALUE])\n",
    "                n = m.search(val) \n",
    "                if n:\n",
    "                    #chart\\block.signal,cpu_link\n",
    "                    chart_block_signal = j[CHART].upper()+'\\\\'+j[BLOCK].upper()+'.'+j[NAME].upper()\n",
    "                    cpu_link = j[CPU]+'_'+val.split()[0] #convert '$LINK PN' => '$LINK'\n",
    "                    #print(chart_block_signal,\"=>\",cpu_link)\n",
    "                    out_df.append([chart_block_signal,cpu_link])\n",
    "            #look for source link in link array\n",
    "            for k in j[LINKS]:\n",
    "                if(k):\n",
    "                    n = m.search(str(k)) \n",
    "                    if n:\n",
    "                        #chart\\block.signal,cpu_link\n",
    "                        chart_block_signal = j[CHART].upper()+'\\\\'+j[BLOCK].upper()+'.'+j[NAME].upper()\n",
    "                        cpu_link = j[CPU]+'_'+str(k).split()[0] #convert '$LINK PN' => '$LINK'\n",
    "                        #print(chart_block_signal,\"=>\",cpu_link)\n",
    "                        out_df.append([chart_block_signal,cpu_link])\n",
    "    return out_df\n",
    "\n",
    "#generate data of all charts and generate data of link sources\n",
    "def sd_build_data_s1(sd_chart_list,data_link_map_df):\n",
    "    \n",
    "    data_list = []\n",
    "    data_link_source_list = []\n",
    "    for i in sd_chart_list:\n",
    "        for (k,v) in sd_chart_list[i].items(): \n",
    "            chart = k.upper()\n",
    "            chart_lines = sd_open_chart(v)\n",
    "            chart_mapping = sd_get_chart_map(chart_lines)\n",
    "            if chart_mapping==-1:\n",
    "                print(\"Parsing '%s' chart with 0 functions\"%(chart))\n",
    "                continue\n",
    "            else:\n",
    "                print(\"Parsing '%s' chart with %s functions\"%(chart,len(chart_mapping)))\n",
    "            \n",
    "            for block_map in chart_mapping:\n",
    "                #generating array 'signal','type_base','inout','type_conv','value','link','chart','block','cpu'\n",
    "                block_lines = chart_lines[chart_mapping[block_map][0]:chart_mapping[block_map][1]]\n",
    "                #get block data: NAME,TYPE_BASE,INOUT,TYPE_CONV,VALUE,CPU,CPU_SOURCE,CPU_LINK,CHART,BLOCK\n",
    "                block_data = sd_get_block_data(block_lines,chart,block_map,data_link_map_df)\n",
    "                if block_data == -1:\n",
    "                    print(\"Parsing cancelled: '%s' chart is not used in SimadynD program\"%(chart))\n",
    "                    break\n",
    "                #print(\"before \",block_data)\n",
    "                #print(\"-- \")\n",
    "                block_data_list = sd_conv_block_data_to_list(block_data)\n",
    "                #print(\"after \",block_data_list)\n",
    "                #print(\"-- \")\n",
    "                #Add block data to accumulation list\n",
    "                data_list.extend(block_data_list)\n",
    "                #create link source array\n",
    "                block_link_source_list = sd_get_source_link(block_data_list)\n",
    "                if len(block_link_source_list)!=0:\n",
    "                    #print(block_link_source_list)\n",
    "                    data_link_source_list.extend(block_link_source_list) \n",
    "    #Convert to DataFrame for easy work\n",
    "    data_link_source_df = pd.DataFrame(data_link_source_list, columns=['chart_block_signal','cpu_link'])\n",
    "    data_df = pd.DataFrame(data_list, columns=['signal','type_base','inout','type_conv','value','cpu',\\\n",
    "                                                         'cpu_source','cpu_link','chart','block','link'])\n",
    "    return data_df,data_link_source_df\n",
    "\n",
    "#parsing mapping file\n",
    "#generate cpu,link db by cpu mapping file\n",
    "def sd_build_cpu_map(sd_chart_list):\n",
    "    data_link_map_list = []\n",
    "    bg_lang_options = {\"EN\":\"Connector list of the function packets\",\n",
    "                       \"DE\":\"Konnektorliste der Funktionspakete\"}\n",
    "    cp = re.compile(r'^\\s+\\d+\\s+([a-zA-Z0-9_-]+)$') #find CPU name in file\n",
    "    bg = re.compile(r'^\\s+\\d+\\s+%s'%(bg_lang_options[SIMADYND_LANG])) # find beginning of link information\n",
    "    en = re.compile(r'^\\s*\\d+\\s+\\*')\n",
    "    ch = re.compile(r'^\\s*\\d+\\s+FP-([a-zA-Z0-9_\\-@]+)')\n",
    "    lk = re.compile(r'^\\s*\\d+\\s+(\\$[a-zA-Z0-9_\\-@]+)\\s+([\\w]+)\\s+((<)|(>))\\s+([\\w]+)\\s+([a-zA-Z0-9_-]+)$')\n",
    "    \n",
    "    for i in sd_chart_list:\n",
    "        for (k,v) in sd_chart_list[i].items():\n",
    "            chart_lines = sd_open_chart(v)\n",
    "            print(\"Parsing cpu file '%s'  \"%(k))\n",
    "            cpu_mark = False\n",
    "            beg_mark = False\n",
    "            end_mark = False\n",
    "            for l in chart_lines:\n",
    "                ##Find CPU name\n",
    "                if not cpu_mark:\n",
    "                    cp_s = cp.search(l)\n",
    "                    if cp_s :\n",
    "                        cpu = cp_s.group(1)\n",
    "                        cpu_mark = True\n",
    "                        print(cpu)   \n",
    "                else:\n",
    "                    if not beg_mark:\n",
    "                        if bg.search(l):\n",
    "                            beg_mark = True\n",
    "                    else:\n",
    "                        #check end\n",
    "                        if en.search(l):\n",
    "                            end_mark = True\n",
    "                            break\n",
    "                        else:\n",
    "                            #main block:\n",
    "                            ch_s = ch.search(l)\n",
    "                            if ch.search(l): #if chart beginning 1739\tFP-MONIW1\n",
    "                                chart = ch_s.group(1)\n",
    "                            else:\n",
    "                                lk_s = lk.search(l)\n",
    "                                if lk_s: #if chart link definition 1744\t   $DMALB1 T5 < PN     PN-D01_P1\n",
    "                                    #'cpu','chart','out','link','cpu_source'\n",
    "                                    data_link_map_list.append([cpu, chart.upper(),lk_s.group(3),lk_s.group(1),lk_s.group(7)])\n",
    "    data_link_map_df = pd.DataFrame(data_link_map_list, columns=['cpu','chart','out','link','cpu_source'])\n",
    "    return data_link_map_df\n",
    "\n",
    "def sd_get_chart_cpu(data_link_map_df,chart):\n",
    "    try:\n",
    "        result = data_link_map_df[data_link_map_df['chart']==chart].iloc[0]['cpu']\n",
    "    except IndexError:\n",
    "        result = -1\n",
    "    return result\n",
    "def sd_get_block_link_source_cpu(data_link_map_df,link,chart):\n",
    "    return data_link_map_df[(data_link_map_df['chart']==chart)&\\\n",
    "                            (data_link_map_df['link']==link)&\\\n",
    "                            (data_link_map_df['out']==\"<\")].iloc[0]['cpu_source']\n",
    "\n",
    "def sd_get_link_partner(data_link_source_df,cpu_link):\n",
    "    try:\n",
    "        return data_link_source_df[(data_link_source_df['cpu_link']==cpu_link)].iloc[0]['chart_block_signal']\n",
    "    except IndexError:\n",
    "        return None\n",
    "    \n",
    "###########LIBRARY CELL###########\n",
    "#find partner link and put in 'value_linked' column.\n",
    "#This column should be used for comparison\n",
    "def sd_rect_data_s1(data_df,data_link_source_df):\n",
    "    def lookup(x):\n",
    "        partner = sd_get_link_partner(data_link_source_df,x)\n",
    "        return partner\n",
    "    data_df['value_linked'] = data_df['cpu_link'].apply(lookup)\n",
    "    return data_df\n",
    "\n",
    "#copy values in 'value_linked' - to get proper view: value or link to other block. \n",
    "#This column should be used for comparison\n",
    "#Also convert in-chart link to absolute representation e.g. ENMESS.Q => MONIW1\\ENMESS.Q\n",
    "def sd_rect_data_s2(data_df):\n",
    "    def lookup(x):\n",
    "        if x['value_linked'] is None:\n",
    "            if re.search(r'^[a-zA-Z0-9_\\-@]+\\.[a-zA-Z0-9_\\-@]+$',str(x['value'])) and not re.search(r'^[0-9]+\\.[0-9]+$',str(x['value'])):\n",
    "                if not x['type_base'] in ['CR','NK','TR','RR']:\n",
    "                    return x['chart']+\"\\\\\"+x['value']\n",
    "                else:\n",
    "                    return x['value']\n",
    "            else:\n",
    "                #convert output 'link' array to string and return to 'value_linked'\n",
    "                #TODO: doesn't work with $links -> should be extended for this case.\n",
    "                if x['value'] is None and x['link']:\n",
    "                    return ','.join(x['link'])\n",
    "                else:\n",
    "                    return x['value']  \n",
    "        else:\n",
    "            return x['value_linked']\n",
    "    data_df['value_linked'] = data_df.apply(lookup,axis = 1)\n",
    "    return data_df\n",
    "\n",
    "\n",
    "###########LIBRARY CELL###########\n",
    "#report generator of comparison of block in all SD1 and SD2 charts\n",
    "def report_find_miss_blocks (sd1_data_sd,sd2_data_sd, to_file = True, timestamp = datetime.datetime.now()):\n",
    "    README_HEADER = COMPARATOR_README +\"\\\n",
    "\\r\\nReport: find missing blocks in sources\\\n",
    "\\r\\nDate ant time of report generation: %s \\\n",
    "\\r\\n===================================================================================\\\n",
    "\\r\\n\"%(str(timestamp))\n",
    "    \n",
    "    def generate_report(f):\n",
    "        print(README_HEADER,file = f) \n",
    "        sd1_chartblock_sel = sd1_data_sd[\"chart\"]+\"/\"+sd1_data_sd[\"block\"]\n",
    "        sd1_uniq_blocks = sd1_chartblock_sel.unique()\n",
    "        #tdc_uniq_blocks = data_tdc['chartblock'].unique()\n",
    "        sd2_chartblock_sel = sd2_data_sd[\"chart\"]+\"/\"+sd2_data_sd[\"block\"]\n",
    "        sd2_uniq_blocks = sd2_chartblock_sel.unique()\n",
    "        #look for A in B\n",
    "        for i in sd1_uniq_blocks:\n",
    "            if not i in sd2_uniq_blocks:\n",
    "                print(\"Missing block in SD#2: \",i,\"\\r\\n\",file = f) \n",
    "        #look for B in A\n",
    "        for i in sd2_uniq_blocks:\n",
    "            if not i in sd1_uniq_blocks:\n",
    "                print(\"Missing block in SD#1: \",i,\"\\r\\n\",file = f) \n",
    "  \n",
    "    if to_file:\n",
    "        file_suffix = \"@_compare_blocks_sd_%s\"%(str(timestamp.date()))\n",
    "        file_prefix = \"report_@\"\n",
    "        try:\n",
    "            # Create target Directory\n",
    "            os.mkdir(os.path.join(PATH_TO_REPORTS))\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        #sys.stdout = open(os.path.join(PATH_TO_REPORTS,(file_prefix+FILE_NAME_DATA1.split(\".\")[0]+file_suffix+\".txt\")), 'w')\n",
    "        with open(os.path.join(PATH_TO_REPORTS,(file_prefix+SD_RACK_NAMES[0]+file_suffix+\".txt\")), 'w') as f: \n",
    "            generate_report(f)\n",
    "    else:\n",
    "        generate_report(sys.stdout)\n",
    "        \n",
    "        \n",
    "###########LIBRARY CELL###########\n",
    "#####report of comparison of all SD blocks inputs, including links\n",
    "\n",
    "        #['BOOL' 'INT' 'WORD' 'SDTIME' 'GLOBAL' 'STRING' 'REAL' 'DINT' 'BYTE' 'DWORD']\n",
    "        #SD types:\n",
    "        #'B1' - BOOL (0/1/link)\n",
    "        #'TF' - Time (ffff.fff[s/min/S/ms])\n",
    "        #'N2' - Integer (ddddd)\n",
    "        #'V2' - Integer HEX\n",
    "        #'MR' - Message link (e.g MESY_1)(Inout = \"-\")\n",
    "        #'NS' - String (Inout = \"-\")\n",
    "        #'O2' - Integer (dddddd)\n",
    "        #'CR' - Hardware connectors, string\n",
    "        #'V4' - Dword HEX\n",
    "        #'NF' - Floating point\n",
    "        #'V1' - Byte HEX   \n",
    "        #'I2' - Integer\n",
    "        #'NK' - Hardware connectors, string (Inout = \"=\")\n",
    "        #'TR' - Telegram transmit connector e.g. !EXM504 (Inout = \"=\")\n",
    "        #'N4' - Integer 32 bits (%/HEX/ddd)\n",
    "        #'RR' - Telegram recieve connector e.g. !T4EX05 (Inout = \"=\") \n",
    "        \n",
    "\n",
    "\n",
    "def report_comp_inputs (s1_inp_data,s2_inp_data, to_file = True, timestamp = datetime.datetime.now()):\n",
    "    README_HEADER = COMPARATOR_README +\"\\\n",
    "\\r\\nReport: compare all SD#1 inputs (including links) with SD#2\\\n",
    "\\r\\nDate ant time of report generation: %s \\\n",
    "\\r\\n===================================================================================\\\n",
    "\\r\\n\"%(str(timestamp))\n",
    "    sd1_data_sd = s1_inp_data.copy()\n",
    "    #data_tdc = inp_data_tdc.copy()\n",
    "    sd2_data_sd = s2_inp_data.copy()\n",
    "    def merge_tdc_link_value(l_value,l_link):\n",
    "        if pd.isnan(l_link):\n",
    "            return l_link\n",
    "        else:\n",
    "            return l_value\n",
    "    \n",
    "    def clean_sd_tdc_str_values(s1_value,s2_value,sd_type,sd_type_conv,chart_block_signal,source_dest_text,f):\n",
    "        #modify HEX function\n",
    "        def twos_complement(hexstr,bits,base=16):\n",
    "            value = int(hexstr,base)\n",
    "            if value & (1 << (bits-1)):\n",
    "                value -= 1 << bits\n",
    "            return value\n",
    " \n",
    "        #for debugging\n",
    "        #print(\"Working on:\",s_value,a_value,sd_type,sd_type_conv)\n",
    "        \n",
    "        #check if values are empty\n",
    "        if  pd.isnull(s1_value):\n",
    "            if pd.isnull(s2_value):\n",
    "                return True\n",
    "            else:\n",
    "                result = False;\n",
    "        else:\n",
    "            if pd.isnull(s2_value):\n",
    "                result = False;\n",
    "            else:\n",
    "                result = s1_value == s2_value;\n",
    "            \n",
    "        if not result:\n",
    "            print(\"\\r\\nDifference found in \",source_dest_text,chart_block_signal,\": \",s1_value,'==>>> ',s2_value,file = f)\n",
    "        return result\n",
    "\n",
    "    def generate_report(f):\n",
    "        print(README_HEADER,file = f) \n",
    "        #this comparator works with following data types and connectors:\n",
    "        #filter sd data frame\n",
    "        sd1_data_sd_filtered = sd1_data_sd[(sd1_data_sd['type_base'].isin(filt_type_base))&(sd1_data_sd['inout'].isin(filt_inout))]\n",
    "        sd2_data_sd_filtered = sd2_data_sd[(sd2_data_sd['type_base'].isin(filt_type_base))&(sd2_data_sd['inout'].isin(filt_inout))]\n",
    "        \n",
    "        sd1_data_sd_filtered['chart_block_signal'] = sd1_data_sd_filtered[\"chart\"]+\"/\"+sd1_data_sd_filtered[\"block\"]+\".\"+sd1_data_sd_filtered[\"signal\"]\n",
    "        sd2_data_sd_filtered['chart_block_signal'] = sd2_data_sd_filtered[\"chart\"]+\"/\"+sd2_data_sd_filtered[\"block\"]+\".\"+sd2_data_sd_filtered[\"signal\"]\n",
    "        \n",
    "        #connect links $XXXXX->$XXXXX\n",
    "        #d = dict(zip(data_tdc['chart_block_signal'].values, data_tdc['value_linked'].values)) #for tdc\n",
    "        d1 = dict(zip(sd2_data_sd_filtered['chart_block_signal'].values, sd2_data_sd_filtered['value_linked'].values))\n",
    "        d2 = dict(zip(sd1_data_sd_filtered['chart_block_signal'].values, sd1_data_sd_filtered['value_linked'].values))\n",
    "        \n",
    "        sd1_data_sd_filtered['val_to_compare'] = sd1_data_sd_filtered['chart_block_signal'].map(d1)\n",
    "        sd1_data_sd_filtered['compare_val_sd'] = sd1_data_sd_filtered.apply(lambda row: clean_sd_tdc_str_values(\\\n",
    "           row['value_linked'], row['val_to_compare'],row['type_base'], row['type_conv'],row['chart_block_signal'],\"SD#1->SD#2 value:\",f), axis=1)\n",
    "        \n",
    "        sd2_data_sd_filtered['val_to_compare'] = sd2_data_sd_filtered['chart_block_signal'].map(d2)\n",
    "        sd2_data_sd_filtered['compare_val_sd'] = sd2_data_sd_filtered.apply(lambda row: clean_sd_tdc_str_values(\\\n",
    "           row['value_linked'], row['val_to_compare'],row['type_base'], row['type_conv'],row['chart_block_signal'],\"SD#2->SD#1 value:\",f), axis=1)\n",
    "        \n",
    "    if to_file:\n",
    "        file_suffix = \"@_compare_inputs_sd_%s\"%(str(timestamp.date()))\n",
    "        file_prefix = \"report_@\"\n",
    "        try:\n",
    "            # Create target Directory\n",
    "            os.mkdir(os.path.join(PATH_TO_REPORTS))\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        #sys.stdout = open(os.path.join(PATH_TO_REPORTS,(file_prefix+FILE_NAME_DATA1.split(\".\")[0]+file_suffix+\".txt\")), 'w')\n",
    "        with open(os.path.join(PATH_TO_REPORTS,(file_prefix+SD_RACK_NAMES[0]+file_suffix+\".txt\")), 'w') as f: \n",
    "            generate_report(f)\n",
    "    else:\n",
    "        generate_report(sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing cpu file '1vx21'  \n",
      "PN-D01_P1\n",
      "Parsing cpu file '2vx21'  \n",
      "PN-D05_P2\n",
      "Parsing cpu file '3vx21'  \n",
      "PN-D07_P3\n",
      "Parsing cpu file '4vx21'  \n",
      "PN-D09_P4\n",
      "Parsing cpu file '5vx21'  \n",
      "PN-D11_P5\n",
      "Parsing cpu file '6vx21'  \n",
      "PN-D13_P6\n",
      "Parsing cpu file '7vx21'  \n",
      "PN-D16_P7\n",
      "Parsing 'WPS__1' chart with 7 functions\n",
      "Parsing cancelled: 'WPS__1' chart is not used in SimadynD program\n",
      "Parsing 'WPS__2' chart with 7 functions\n",
      "Parsing cancelled: 'WPS__2' chart is not used in SimadynD program\n",
      "Parsing 'WPS__3' chart with 7 functions\n",
      "Parsing cancelled: 'WPS__3' chart is not used in SimadynD program\n",
      "Parsing 'WPS__4' chart with 7 functions\n",
      "Parsing cancelled: 'WPS__4' chart is not used in SimadynD program\n",
      "Parsing 'WPS__5' chart with 7 functions\n",
      "Parsing cancelled: 'WPS__5' chart is not used in SimadynD program\n",
      "Parsing 'WPS__6' chart with 7 functions\n",
      "Parsing cancelled: 'WPS__6' chart is not used in SimadynD program\n",
      "Parsing 'WPS__7' chart with 7 functions\n",
      "Parsing cancelled: 'WPS__7' chart is not used in SimadynD program\n",
      "Parsing 'WR1C_2' chart with 109 functions\n",
      "Parsing 'WR1LT6' chart with 133 functions\n",
      "Parsing cancelled: 'WR1LT6' chart is not used in SimadynD program\n",
      "Parsing 'WR1L_6' chart with 149 functions\n",
      "Parsing 'WR1R_2' chart with 124 functions\n",
      "Parsing 'WR2C_3' chart with 102 functions\n",
      "Parsing 'WR2L_6' chart with 148 functions\n",
      "Parsing 'WR2R_3' chart with 123 functions\n",
      "Parsing 'WR3C_4' chart with 102 functions\n",
      "Parsing 'WR3L_6' chart with 148 functions\n",
      "Parsing 'WR3R_4' chart with 120 functions\n",
      "Parsing 'WREXS5' chart with 137 functions\n",
      "Parsing 'WRL__5' chart with 271 functions\n",
      "Parsing 'WRS__6' chart with 105 functions\n",
      "Parsing 'WRTRK5' chart with 92 functions\n",
      "Parsing 'XWCC_5' chart with 16 functions\n",
      "Parsing 'XWCC_6' chart with 51 functions\n",
      "Parsing 'OUTHW7' chart with 235 functions\n",
      "Parsing 'OUTSW7' chart with 54 functions\n",
      "Parsing 'PAR__1' chart with 11 functions\n",
      "Parsing 'PAR__2' chart with 11 functions\n",
      "Parsing 'PAR__3' chart with 11 functions\n",
      "Parsing 'PAR__4' chart with 11 functions\n",
      "Parsing 'PAR__5' chart with 11 functions\n",
      "Parsing 'PAR__6' chart with 53 functions\n",
      "Parsing 'PAR__7' chart with 11 functions\n",
      "Parsing 'PBL__6' chart with 150 functions\n",
      "Parsing 'PRCP_6' chart with 124 functions\n",
      "Parsing 'PRDC_1' chart with 93 functions\n",
      "Parsing 'PRL__1' chart with 270 functions\n",
      "Parsing 'PROC_1' chart with 95 functions\n",
      "Parsing 'PRR__1' chart with 256 functions\n",
      "Parsing 'PRS__6' chart with 202 functions\n",
      "Parsing 'PRTEM7' chart with 52 functions\n",
      "Parsing 'PRT__6' chart with 190 functions\n",
      "Parsing 'PTL__6' chart with 139 functions\n",
      "Parsing 'RACK_7' chart with 22 functions\n",
      "Parsing 'RECT_6' chart with 217 functions\n",
      "Parsing 'SDINT6' chart with 6 functions\n",
      "Parsing 'SERV_1' chart with 10 functions\n",
      "Parsing 'SERV_2' chart with 8 functions\n",
      "Parsing cancelled: 'SERV_2' chart is not used in SimadynD program\n",
      "Parsing 'SERV_3' chart with 8 functions\n",
      "Parsing cancelled: 'SERV_3' chart is not used in SimadynD program\n",
      "Parsing 'SERV_4' chart with 8 functions\n",
      "Parsing cancelled: 'SERV_4' chart is not used in SimadynD program\n",
      "Parsing 'SERV_5' chart with 10 functions\n",
      "Parsing 'SERV_6' chart with 8 functions\n",
      "Parsing cancelled: 'SERV_6' chart is not used in SimadynD program\n",
      "Parsing 'SERV_7' chart with 10 functions\n",
      "Parsing 'SUC2_7' chart with 65 functions\n",
      "Parsing 'TEMP_7' chart with 48 functions\n",
      "Parsing 'TRC__6' chart with 52 functions\n",
      "Parsing 'CTRC_7' chart with 19 functions\n",
      "Parsing 'CTRS_7' chart with 108 functions\n",
      "Parsing 'DIA__6' chart with 126 functions\n",
      "Parsing 'EXP__5' chart with 149 functions\n",
      "Parsing 'FHADO7' chart with 186 functions\n",
      "Parsing 'INHW_5' chart with 2 functions\n",
      "Parsing 'INHW_6' chart with 7 functions\n",
      "Parsing 'INHW_7' chart with 548 functions\n",
      "Parsing 'INSW_7' chart with 52 functions\n",
      "Parsing 'MAL__6' chart with 316 functions\n",
      "Parsing 'MAS__6' chart with 209 functions\n",
      "Parsing 'MAT__6' chart with 180 functions\n",
      "Parsing 'MESY_1' chart with 30 functions\n",
      "Parsing 'MESY_2' chart with 10 functions\n",
      "Parsing 'MESY_3' chart with 10 functions\n",
      "Parsing 'MESY_4' chart with 10 functions\n",
      "Parsing 'MESY_5' chart with 26 functions\n",
      "Parsing 'MESY_6' chart with 94 functions\n",
      "Parsing 'MESY_7' chart with 124 functions\n",
      "Parsing 'MMID_1' chart with 24 functions\n",
      "Parsing 'MMID_2' chart with 2 functions\n",
      "Parsing 'MMID_3' chart with 2 functions\n",
      "Parsing 'MMID_4' chart with 2 functions\n",
      "Parsing 'MMID_5' chart with 52 functions\n",
      "Parsing 'MMID_6' chart with 251 functions\n",
      "Parsing 'MMID_7' chart with 10 functions\n",
      "Parsing 'MOV__6' chart with 429 functions\n",
      "Parsing '@SND_1' chart with 2 functions\n",
      "Parsing cancelled: '@SND_1' chart is not used in SimadynD program\n",
      "Parsing '@SND_2' chart with 2 functions\n",
      "Parsing cancelled: '@SND_2' chart is not used in SimadynD program\n",
      "Parsing '@SND_3' chart with 2 functions\n",
      "Parsing cancelled: '@SND_3' chart is not used in SimadynD program\n",
      "Parsing '@SND_4' chart with 2 functions\n",
      "Parsing cancelled: '@SND_4' chart is not used in SimadynD program\n",
      "Parsing '@SND_5' chart with 2 functions\n",
      "Parsing '@SND_6' chart with 2 functions\n",
      "Parsing '@SND_7' chart with 9 functions\n",
      "Parsing 'CHNL_6' chart with 171 functions\n",
      "Parsing 'COL__6' chart with 258 functions\n",
      "Parsing cpu file '1vx21'  \n",
      "PN-D01_P1\n",
      "Parsing cpu file '2vx21'  \n",
      "PN-D05_P2\n",
      "Parsing cpu file '3vx21'  \n",
      "PN-D07_P3\n",
      "Parsing cpu file '4vx21'  \n",
      "PN-D09_P4\n",
      "Parsing cpu file '5vx21'  \n",
      "PN-D11_P5\n",
      "Parsing cpu file '6vx21'  \n",
      "PN-D13_P6\n",
      "Parsing cpu file '7vx21'  \n",
      "PN-D16_P7\n",
      "Parsing 'WPS__1' chart with 7 functions\n",
      "Parsing cancelled: 'WPS__1' chart is not used in SimadynD program\n",
      "Parsing 'WPS__2' chart with 7 functions\n",
      "Parsing cancelled: 'WPS__2' chart is not used in SimadynD program\n",
      "Parsing 'WPS__3' chart with 7 functions\n",
      "Parsing cancelled: 'WPS__3' chart is not used in SimadynD program\n",
      "Parsing 'WPS__4' chart with 7 functions\n",
      "Parsing cancelled: 'WPS__4' chart is not used in SimadynD program\n",
      "Parsing 'WPS__5' chart with 7 functions\n",
      "Parsing cancelled: 'WPS__5' chart is not used in SimadynD program\n",
      "Parsing 'WPS__6' chart with 7 functions\n",
      "Parsing cancelled: 'WPS__6' chart is not used in SimadynD program\n",
      "Parsing 'WPS__7' chart with 7 functions\n",
      "Parsing cancelled: 'WPS__7' chart is not used in SimadynD program\n",
      "Parsing 'WR1C_2' chart with 109 functions\n",
      "Parsing 'WR1LT6' chart with 133 functions\n",
      "Parsing cancelled: 'WR1LT6' chart is not used in SimadynD program\n",
      "Parsing 'WR1L_6' chart with 149 functions\n",
      "Parsing 'WR1R_2' chart with 124 functions\n",
      "Parsing 'WR2C_3' chart with 102 functions\n",
      "Parsing 'WR2L_6' chart with 148 functions\n",
      "Parsing 'WR2R_3' chart with 123 functions\n",
      "Parsing 'WR3C_4' chart with 102 functions\n",
      "Parsing 'WR3L_6' chart with 148 functions\n",
      "Parsing 'WR3R_4' chart with 120 functions\n",
      "Parsing 'WREXS5' chart with 137 functions\n",
      "Parsing 'WRL__5' chart with 271 functions\n",
      "Parsing 'WRS__6' chart with 105 functions\n",
      "Parsing 'WRTRK5' chart with 92 functions\n",
      "Parsing 'XWCC_5' chart with 16 functions\n",
      "Parsing 'XWCC_6' chart with 51 functions\n",
      "Parsing 'MOV__6' chart with 429 functions\n",
      "Parsing 'OUTHW7' chart with 235 functions\n",
      "Parsing 'OUTSW7' chart with 54 functions\n",
      "Parsing 'PAR__1' chart with 11 functions\n",
      "Parsing 'PAR__2' chart with 11 functions\n",
      "Parsing 'PAR__3' chart with 11 functions\n",
      "Parsing 'PAR__4' chart with 11 functions\n",
      "Parsing 'PAR__5' chart with 11 functions\n",
      "Parsing 'PAR__6' chart with 53 functions\n",
      "Parsing 'PAR__7' chart with 11 functions\n",
      "Parsing 'PBL__6' chart with 150 functions\n",
      "Parsing 'PRCP_6' chart with 124 functions\n",
      "Parsing 'PRDC_1' chart with 93 functions\n",
      "Parsing 'PRL__1' chart with 270 functions\n",
      "Parsing 'PROC_1' chart with 95 functions\n",
      "Parsing 'PRR__1' chart with 256 functions\n",
      "Parsing 'PRS__6' chart with 202 functions\n",
      "Parsing 'PRTEM7' chart with 52 functions\n",
      "Parsing 'PRT__6' chart with 190 functions\n",
      "Parsing 'PTL__6' chart with 139 functions\n",
      "Parsing 'RACK_7' chart with 22 functions\n",
      "Parsing 'RECT_6' chart with 217 functions\n",
      "Parsing 'SDINT6' chart with 6 functions\n",
      "Parsing 'SERV_1' chart with 10 functions\n",
      "Parsing 'SERV_2' chart with 8 functions\n",
      "Parsing cancelled: 'SERV_2' chart is not used in SimadynD program\n",
      "Parsing 'SERV_3' chart with 8 functions\n",
      "Parsing cancelled: 'SERV_3' chart is not used in SimadynD program\n",
      "Parsing 'SERV_4' chart with 8 functions\n",
      "Parsing cancelled: 'SERV_4' chart is not used in SimadynD program\n",
      "Parsing 'SERV_5' chart with 10 functions\n",
      "Parsing 'SERV_6' chart with 8 functions\n",
      "Parsing cancelled: 'SERV_6' chart is not used in SimadynD program\n",
      "Parsing 'SERV_7' chart with 10 functions\n",
      "Parsing 'SUC2_7' chart with 65 functions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing 'TEMP_7' chart with 48 functions\n",
      "Parsing 'TRC__6' chart with 52 functions\n",
      "Parsing 'CTRC_7' chart with 19 functions\n",
      "Parsing 'CTRS_7' chart with 108 functions\n",
      "Parsing 'DIA__6' chart with 126 functions\n",
      "Parsing 'EXP__5' chart with 149 functions\n",
      "Parsing 'FHADO7' chart with 186 functions\n",
      "Parsing 'INHW_5' chart with 2 functions\n",
      "Parsing 'INHW_6' chart with 7 functions\n",
      "Parsing 'INHW_7' chart with 548 functions\n",
      "Parsing 'INSW_7' chart with 52 functions\n",
      "Parsing 'MAL__6' chart with 316 functions\n",
      "Parsing 'MAS__6' chart with 209 functions\n",
      "Parsing 'MAT__6' chart with 180 functions\n",
      "Parsing 'MESY_1' chart with 30 functions\n",
      "Parsing 'MESY_2' chart with 10 functions\n",
      "Parsing 'MESY_3' chart with 10 functions\n",
      "Parsing 'MESY_4' chart with 10 functions\n",
      "Parsing 'MESY_5' chart with 26 functions\n",
      "Parsing 'MESY_6' chart with 94 functions\n",
      "Parsing 'MESY_7' chart with 124 functions\n",
      "Parsing 'MMID_1' chart with 24 functions\n",
      "Parsing 'MMID_2' chart with 2 functions\n",
      "Parsing 'MMID_3' chart with 2 functions\n",
      "Parsing 'MMID_4' chart with 2 functions\n",
      "Parsing 'MMID_5' chart with 52 functions\n",
      "Parsing 'MMID_6' chart with 251 functions\n",
      "Parsing 'MMID_7' chart with 10 functions\n",
      "Parsing '@SND_1' chart with 2 functions\n",
      "Parsing cancelled: '@SND_1' chart is not used in SimadynD program\n",
      "Parsing '@SND_2' chart with 2 functions\n",
      "Parsing cancelled: '@SND_2' chart is not used in SimadynD program\n",
      "Parsing '@SND_3' chart with 2 functions\n",
      "Parsing cancelled: '@SND_3' chart is not used in SimadynD program\n",
      "Parsing '@SND_4' chart with 2 functions\n",
      "Parsing cancelled: '@SND_4' chart is not used in SimadynD program\n",
      "Parsing '@SND_5' chart with 2 functions\n",
      "Parsing '@SND_6' chart with 2 functions\n",
      "Parsing '@SND_7' chart with 9 functions\n",
      "Parsing 'CHNL_6' chart with 171 functions\n",
      "Parsing 'COL__6' chart with 258 functions\n"
     ]
    }
   ],
   "source": [
    "###########EXECUTION CELL###########\n",
    "sd1_chart_list = sd_get_chart_list(PATH_TO_STRUCG_1, SD_RACK_NAMES=SD_RACK_NAMES) \n",
    "sd1_cpu_charts_list = sd_get_cpu_charts_list(PATH_TO_STRUCG_1, SD_RACK_NAMES=SD_RACK_NAMES) \n",
    "sd2_chart_list = sd_get_chart_list(PATH_TO_STRUCG_2, SD_RACK_NAMES=SD_RACK_NAMES) \n",
    "sd2_cpu_charts_list = sd_get_cpu_charts_list(PATH_TO_STRUCG_2, SD_RACK_NAMES=SD_RACK_NAMES) \n",
    "\n",
    "###########EXECUTION CELL###########\n",
    "#creating row data DataFrame \"sd1_data_s1\" from chart list\n",
    "sd1_data_lm = sd_build_cpu_map(sd1_cpu_charts_list)\n",
    "sd1_data_s1,sd1_data_ls1 = sd_build_data_s1(sd1_chart_list,sd1_data_lm)\n",
    "sd1_data_s1[\"block\"] = sd1_data_s1[\"block\"].astype(str)\n",
    "\n",
    "###########EXECUTION CELL###########\n",
    "#creating row data DataFrame \"sd2_data_s1\" from chart list\n",
    "sd2_data_lm = sd_build_cpu_map(sd2_cpu_charts_list)\n",
    "sd2_data_s1,sd2_data_ls1 = sd_build_data_s1(sd2_chart_list,sd2_data_lm)\n",
    "sd2_data_s1[\"block\"] = sd2_data_s1[\"block\"].astype(str)\n",
    "\n",
    "###########EXECUTION CELL###########\n",
    "#find links for sd1\n",
    "sd1_data_s2 = sd_rect_data_s1(sd1_data_s1.copy(),sd1_data_ls1)\n",
    "sd1_data_s3 = sd_rect_data_s2(sd1_data_s2.copy())\n",
    "\n",
    "###########EXECUTION CELL###########\n",
    "#find links for sd2\n",
    "sd2_data_s2 = sd_rect_data_s1(sd2_data_s1.copy(),sd2_data_ls1)\n",
    "sd2_data_s3 = sd_rect_data_s2(sd2_data_s2.copy())\n",
    "\n",
    "#############EXECUTION GENERATE REPORT report_find_miss_blocks############\n",
    "#report_find_miss_blocks(data_s2,data_a1,to_file = True)\n",
    "report_find_miss_blocks(sd1_data_s2,sd2_data_s2,to_file = True)\n",
    "\n",
    "#############EXECUTION GENERATE REPORT report_comp_inputs############\n",
    "#report_comp_inputs(data_s3,data_a1,to_file = True)\n",
    "report_comp_inputs(sd1_data_s3,sd2_data_s3,to_file = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
